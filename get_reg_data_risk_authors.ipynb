{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import unidecode\n",
    "import reverse_geocode\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from patsy import dmatrices\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from ethnicolr import pred_census_ln, pred_wiki_name\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_keep = ['Mention Date', 'Mention Title', 'Outlet or Author', 'Mention URL', 'DOI', 'Research Output Title', 'Journal/Collection Title', 'Subjects (FoR)', 'Affiliations (GRID)', 'Publication Date', 'Altmetric Attention Score']\n",
    "data_root = '/shared/0/projects/news-quotes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(filename):\n",
    "    '''return absolute file path'''\n",
    "    return os.path.join(data_root, filename)\n",
    "\n",
    "def yield_one_line(filename, delimiter = '\\t', quote = csv.QUOTE_NONE):\n",
    "    '''a generator which produce one line of a given file'''\n",
    "    filepath = get_path(filename)\n",
    "    with open(filepath, 'r') as file:\n",
    "        print('processing %s...' %(filepath))\n",
    "        reader = csv.reader(file, delimiter=delimiter, quoting=quote)\n",
    "        for row in reader:\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean journal title, affiliation title\n",
    "table = str.maketrans(\",'&:-\", \"     \")\n",
    "prefix = ['Professor', 'Prof.', 'Doctor', 'Dr.', 'Mr.', 'Miss', 'Ms.', 'Mrs.']\n",
    "name_filter = set(['consortium', 'collaboration', 'collaboration*', 'editor', 'bank'])\n",
    "last_name_fix = {\n",
    "    'join(': 'Berle',\n",
    "    'è‘‰)': 'Ip',\n",
    "    'A.)': 'Boyle',\n",
    "    'M.)': 'Lenton',\n",
    "    'Tian(': 'Tian',\n",
    "    ')Guangping': 'Guangping'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_name(name):\n",
    "    words = name.split()\n",
    "    # must has first and last name to query the API\n",
    "    if len(words) <= 1:\n",
    "        payload = 'invalid'\n",
    "    else:\n",
    "        payload = {'Fname': words[0], 'Lname': words[-1]}\n",
    "        # C. Kirabo Jackson\n",
    "        if len(words) >= 3:\n",
    "            # C or C.\n",
    "            if len(words[0]) == 1 or (len(words[0]) == 2 and words[0][1] == '.'):\n",
    "                # not C. J. Jackson; but C. Del Jackson\n",
    "                if len(words[1]) > 2 or (len(words[1]) == 2 and words[1][1] != '.'):\n",
    "                    given = words[1]\n",
    "                    family = words[-1]\n",
    "                    payload = {'Fname': given, 'Lname': family}\n",
    "    return payload\n",
    "        \n",
    "def get_year_gap(row):\n",
    "    url, doi = row['url'], row['doi']\n",
    "    try:\n",
    "        date1 = datetime.strptime(urls_date[url][:10], '%Y-%m-%d')\n",
    "        date2 = datetime.strptime(dois_date[doi][:10], '%Y-%m-%d')\n",
    "        num_year = (date1-date2).days//365\n",
    "        return num_year\n",
    "    except:\n",
    "        return np.NaN\n",
    "    \n",
    "def get_journal_rank(journal):\n",
    "    if journal == 'unknown':\n",
    "        return np.NaN\n",
    "    else:\n",
    "        nname = norm_string(journal)\n",
    "        if nname in journal_impact:\n",
    "            return journal_impact[nname]\n",
    "        else:\n",
    "            return np.NaN\n",
    "        \n",
    "def get_journal_cate(journal):\n",
    "    if journal in top_journals or journal == 'unknown':\n",
    "        return journal\n",
    "    else:\n",
    "        return 'lose journal'\n",
    "\n",
    "def get_affi_name(affis):\n",
    "    affi_li = affis.split('|')\n",
    "    univs = []\n",
    "    for affi_id in affi_li:\n",
    "        if affi_id in affi_name:\n",
    "            univs.append(affi_name[affi_id])\n",
    "    if len(univs) == 0:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return '|'.join(univs)\n",
    "    \n",
    "def get_affi_cate(affis):\n",
    "    affi_li = affis.split('|')\n",
    "    cate_li = set()\n",
    "    for affi_id in affi_li:\n",
    "        if affi_id in affi_country:\n",
    "            country = affi_country[affi_id]\n",
    "            if country == 'United States':\n",
    "                cate_li.add('domestic')\n",
    "            else:\n",
    "                cate_li.add('international')\n",
    "        else:\n",
    "            cate_li.add('unknown')\n",
    "    if 'domestic' in cate_li:\n",
    "        return 'domestic'\n",
    "    elif 'international' in cate_li:\n",
    "        return 'international'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "        \n",
    "def get_affi_rank(affis):\n",
    "    affi_li = affis.split('|')\n",
    "    rank_li = []\n",
    "    for affi_id in affi_li:\n",
    "        if affi_id in affi_rank:\n",
    "            rank_li.append(affi_rank[affi_id])\n",
    "    if len(rank_li) == 0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return min(rank_li)\n",
    "\n",
    "def get_author_rank(aid):\n",
    "    if aid in aid_metric:\n",
    "        return aid_metric[aid][0]\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "def norm_string(aff_name):\n",
    "    aff_name = aff_name.lower().translate(table)\n",
    "    aff_name = ' '.join(aff_name.split())\n",
    "    return aff_name\n",
    "    \n",
    "def get_news_length(url):\n",
    "    return len(urls_text[url].split(\" \"))\n",
    "\n",
    "def get_last_name_feats(name):\n",
    "    # family name length and prob.\n",
    "    feats = [0, 0]\n",
    "    name_tupe = get_author_name(name)\n",
    "    if type(name_tupe) == dict:\n",
    "        family = name_tupe['Lname']\n",
    "        if family.lower() in name_filter:\n",
    "            # org\n",
    "            feats[0] = len(name)\n",
    "        else:\n",
    "            # length\n",
    "            feats[0] = len(family)\n",
    "            # census prob\n",
    "            family_u = family.upper()\n",
    "            if family_u in family_freq:\n",
    "                feats[1] = family_freq[family_u]\n",
    "    # invalid: single-word-name\n",
    "    else:\n",
    "        feats[0] = len(name)\n",
    "    return feats\n",
    "\n",
    "def get_author_eth_gen(name):\n",
    "    # invalid: single-word-name\n",
    "    feats = ['unknown', 'unknown']\n",
    "    name_tupe = get_author_name(name)\n",
    "    if type(name_tupe) == dict:\n",
    "        family = name_tupe['Lname']\n",
    "        # The XXX Collaboration would go to API as well since the Lname is Collaboration.\n",
    "        if family.lower() in name_filter:\n",
    "            feats = ['org', 'org']\n",
    "        else:\n",
    "            if name in nname_eth_gen:\n",
    "                # ethnicity\n",
    "                major = nname_eth_gen[name]['Ethnea'].split('-')[0]\n",
    "                if major != \"ERROR\" and major != 'UNKNOWN' and major != 'TOOSHORT':\n",
    "                    feats[0] = major\n",
    "                # gender\n",
    "                gender = nname_eth_gen[name]['Genni']\n",
    "                if gender != '-':\n",
    "                    feats[1] = gender\n",
    "    return feats\n",
    "\n",
    "def get_reporter_eth_gen(name):\n",
    "    feats = ['unknown', 'unknown']\n",
    "    if name != 'unknown':\n",
    "        if name in reporter_eth_gen:\n",
    "            # ethnicity\n",
    "            major = reporter_eth_gen[name]['Ethnea'].split('-')[0]\n",
    "            if major != \"ERROR\" and major != 'UNKNOWN' and major != 'TOOSHORT':\n",
    "                feats[0] = major\n",
    "            # gender\n",
    "            gender = reporter_eth_gen[name]['Genni']\n",
    "            if gender != '-':\n",
    "                feats[1] = gender\n",
    "    return feats\n",
    "\n",
    "def is_correspond_author(row):\n",
    "    doi, seq_num = row['doi'], row['author_seq_num']\n",
    "    if doi in doi_wos_authors:\n",
    "        ca_list = doi_wos_authors[doi]['ca_pos_list']\n",
    "        if seq_num in ca_list:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "    \n",
    "# note: this func treats single-word name differently (e.g., \"He\" vs. \"Hao He\")\n",
    "def check_aut_mentioned(row):\n",
    "    url, name = row['url'], row['author_name']\n",
    "    text = urls_text[url]\n",
    "    text = text[:int(0.9*len(text))]\n",
    "    payload = get_author_name(name)\n",
    "    # single-word name\n",
    "    if payload == 'invalid':\n",
    "        # ignore single-word name such as \"L\", \"Do\".\n",
    "        if len(name) >= 3:\n",
    "            if name in text:\n",
    "                return 'yes'\n",
    "            else:\n",
    "                return 'no'\n",
    "        else:\n",
    "            return 'drop'\n",
    "    else:\n",
    "        given, family = payload['Fname'], payload['Lname']\n",
    "        if len(family) == 1:\n",
    "            return 'drop'\n",
    "        elif family == 'He' or family == 'She':\n",
    "            for pre in prefix:\n",
    "                pattern = r\"\\b%s %s\\b\"%(pre, family)\n",
    "                if re.search(pattern, text):\n",
    "                    return 'yes'\n",
    "            else:\n",
    "                return 'drop'\n",
    "        else:\n",
    "            if family in last_name_fix:\n",
    "                family = last_name_fix[family]\n",
    "            pattern = r\"\\b%s\\b\"%family\n",
    "            try:\n",
    "                if re.search(pattern, text):\n",
    "                    return 'yes'\n",
    "                else:\n",
    "                    return 'no'\n",
    "            except:\n",
    "                # print(name, family)\n",
    "                return 'drop'\n",
    "        \n",
    "def get_y(mstring):\n",
    "    if 'yes' in mstring:\n",
    "        return 1\n",
    "    elif 'no' in mstring:\n",
    "        return 0\n",
    "    else:\n",
    "        return mstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load news content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_text = {}\n",
    "\n",
    "with open(data_root+'crawl_news/url_text_clean.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        url, text = row['url'], row['text']\n",
    "        urls_text[url] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520061"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read mentions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = []\n",
    "# each row (a mention) has non-empty url (see `alt_news_mention_dump.ipynb`)\n",
    "with open(data_root+\"news_mentions.json\", 'r') as ffile:\n",
    "    for row_data in ffile:\n",
    "        row_data = json.loads(row_data)\n",
    "        row = [row_data[col] for col in cols_keep]\n",
    "        combined_csv.append(row)\n",
    "combined_csv = pd.DataFrame(combined_csv, columns=cols_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4205331"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list(set(combined_csv['Mention URL'].tolist()))\n",
    "dois = list(set(combined_csv['DOI'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. of unique news articles: 2936447\n",
      "num. of unique journal papers: 787213\n",
      "num. of mentions: 4205331\n"
     ]
    }
   ],
   "source": [
    "print('num. of unique news articles: %d'%len(urls))\n",
    "print('num. of unique journal papers: %d'%len(dois))\n",
    "print('num. of mentions: %d'%len(combined_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "288 U.S. outlets with cleaned news stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = combined_csv.loc[combined_csv['Mention URL'].isin(urls_text)]\n",
    "combined_csv.index = range(len(combined_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mention Date</th>\n",
       "      <th>Mention Title</th>\n",
       "      <th>Outlet or Author</th>\n",
       "      <th>Mention URL</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Research Output Title</th>\n",
       "      <th>Journal/Collection Title</th>\n",
       "      <th>Subjects (FoR)</th>\n",
       "      <th>Affiliations (GRID)</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Altmetric Attention Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02T07:00:00+00:00</td>\n",
       "      <td>â€˜Nanoscavengersâ€™ could protect people from sar...</td>\n",
       "      <td>Science/AAAS</td>\n",
       "      <td>http://ct.moreover.com/?a=38139183068&amp;p=1pl&amp;v=...</td>\n",
       "      <td>10.1126/scitranslmed.aau7091</td>\n",
       "      <td>Nanoscavenger provides long-term prophylactic ...</td>\n",
       "      <td>Science Translational Medicine</td>\n",
       "      <td>Medical And Health Sciences; Biological Sciences</td>\n",
       "      <td></td>\n",
       "      <td>2019-01-02T00:00:00+00:00</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mention Date  \\\n",
       "0  2019-01-02T07:00:00+00:00   \n",
       "\n",
       "                                       Mention Title Outlet or Author  \\\n",
       "0  â€˜Nanoscavengersâ€™ could protect people from sar...     Science/AAAS   \n",
       "\n",
       "                                         Mention URL  \\\n",
       "0  http://ct.moreover.com/?a=38139183068&p=1pl&v=...   \n",
       "\n",
       "                            DOI  \\\n",
       "0  10.1126/scitranslmed.aau7091   \n",
       "\n",
       "                               Research Output Title  \\\n",
       "0  Nanoscavenger provides long-term prophylactic ...   \n",
       "\n",
       "         Journal/Collection Title  \\\n",
       "0  Science Translational Medicine   \n",
       "\n",
       "                                     Subjects (FoR) Affiliations (GRID)  \\\n",
       "0  Medical And Health Sciences; Biological Sciences                       \n",
       "\n",
       "            Publication Date  Altmetric Attention Score  \n",
       "0  2019-01-02T00:00:00+00:00                       84.9  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.replace(np.nan, '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EurekAlert!                                       63007\n",
      "Science Daily                                     44088\n",
      "Technology.org                                    21655\n",
      "Yahoo! News                                       20532\n",
      "Health Medicinet                                  18462\n",
      "Huffington Post                                   17558\n",
      "Newswise                                          15694\n",
      "Physician's Briefing                              15198\n",
      "Health Canal                                      14436\n",
      "MSN                                               13361\n",
      "New York Times                                    10961\n",
      "Nanowerk                                          10372\n",
      "Futurity                                          10085\n",
      "Medical Daily                                     9245\n",
      "Vice                                              8979\n",
      "Drugs.com                                         8736\n",
      "Business Insider                                  8586\n",
      "Scientific American                               8178\n",
      "Washington Post                                   7843\n",
      "Technology Networks                               7468\n",
      "UPI.com                                           6934\n",
      "Science Alert                                     6826\n",
      "Inverse                                           6603\n",
      "Nature World News                                 6452\n",
      "The Epoch Times                                   6302\n",
      "Quartz                                            6150\n",
      "Science/AAAS                                      6105\n",
      "TODAY                                             5895\n",
      "Doctors Lounge                                    5798\n",
      "USNews.com                                        5512\n",
      "Benzinga                                          5417\n",
      "Newsweek                                          5403\n",
      "The Atlantic                                      5367\n",
      "Sign of the Times                                 5303\n",
      "Yahoo!                                            4975\n",
      "Salon                                             4946\n",
      "Sci-News                                          4888\n",
      "Vox.com                                           4782\n",
      "Tech Times                                        4749\n",
      "Science World Report                              4705\n",
      "Yahoo! Finance USA                                4562\n",
      "The Raw Story                                     4556\n",
      "CNN News                                          4524\n",
      "Breitbart News Network                            4139\n",
      "Journalist's Resource                             3977\n",
      "FOX News                                          3911\n",
      "Smithsonian Magazine                              3792\n",
      "Science 2.0                                       3766\n",
      "American Physical Society - Physics               3621\n",
      "Sky Nightly                                       3592\n",
      "LiveScience                                       3563\n",
      "7th Space Family Portal                           3531\n",
      "International Business Times                      3504\n",
      "Bustle                                            3408\n",
      "PR Newswire                                       3404\n",
      "Biospace                                          3391\n",
      "Medium US                                         3343\n",
      "National Geographic                               3103\n",
      "NBC News                                          3000\n",
      "UBM Medica                                        2785\n",
      "Pediatric News                                    2696\n",
      "redOrbit                                          2622\n",
      "The ASCO Post                                     2607\n",
      "2 Minute Medicine                                 2590\n",
      "Medicinenet                                       2590\n",
      "Psych Central                                     2583\n",
      "Headlines & Global News                           2544\n",
      "Real Clear Science                                2523\n",
      "Lab Manager                                       2502\n",
      "Space Daily                                       2425\n",
      "Alternet                                          2386\n",
      "Oncology Nurse Advisor                            2365\n",
      "TIME Magazine                                     2343\n",
      "USA Today                                         2244\n",
      "Physician's Weekly                                2201\n",
      "Google News                                       2125\n",
      "The Inquisitr                                     2116\n",
      "Slate Magazine                                    2079\n",
      "KPBS                                              2023\n",
      "NPR                                               1980\n",
      "SPIE Newsroom                                     1948\n",
      "Pacific Standard                                  1910\n",
      "Health Day                                        1878\n",
      "PBS                                               1864\n",
      "Environmental News Network                        1860\n",
      "Kansas Public Radio                               1841\n",
      "New York Post                                     1839\n",
      "Arstechnica                                       1831\n",
      "Harvard Business Review                           1749\n",
      "Centre for Disease Research and Policy            1741\n",
      "EarthSky                                          1712\n",
      "Becker's Hospital Review                          1687\n",
      "Mother Nature Network                             1683\n",
      "Oregon Public Broadcasting                        1665\n",
      "CNET                                              1633\n",
      "WebMD News                                        1629\n",
      "Mongabay                                          1590\n",
      "Business Wire                                     1576\n",
      "Action News Now                                   1553\n",
      "Psychology Today                                  1547\n",
      "AJMC                                              1543\n",
      "ECN                                               1542\n",
      "Georgia Public Radio                              1540\n",
      "Wyoming Public Radio                              1530\n",
      "Iowa Public Radio                                 1528\n",
      "Fight Aging!                                      1527\n",
      "WVPE                                              1524\n",
      "Wired.com                                         1506\n",
      "Kansas City University Radio                      1504\n",
      "CBS News                                          1496\n",
      "MIT News                                          1489\n",
      "Tri States Public Radio                           1463\n",
      "Homeland Security News Wire                       1446\n",
      "Philly.com                                        1445\n",
      "Guardian Liberty Voice                            1398\n",
      "Becker's Spine Review                             1397\n",
      "KRWG TV/FM                                        1393\n",
      "Carbon Brief                                      1336\n",
      "Space.com                                         1335\n",
      "WUNC                                              1330\n",
      "Christian Science Monitor                         1323\n",
      "WJCT                                              1306\n",
      "newsmax.com                                       1303\n",
      "North East Public Radio                           1298\n",
      "Everyday Health                                   1296\n",
      "WKAR                                              1287\n",
      "KTEP El Paso                                      1283\n",
      "MinnPost                                          1272\n",
      "GEN                                               1272\n",
      "The Hill                                          1260\n",
      "Infection Control Today                           1256\n",
      "KERA News                                         1252\n",
      "WYPR                                              1244\n",
      "Runner's World                                    1241\n",
      "Delmarva Public Radio                             1220\n",
      "Boise State Public Radio                          1209\n",
      "Northern Public Radio                             1204\n",
      "Newser                                            1203\n",
      "Fast Company                                      1197\n",
      "Clinical Advisor                                  1173\n",
      "BioTech Gate                                      1165\n",
      "MIT Technology Review                             1146\n",
      "Omaha Public Radio                                1146\n",
      "Seed Daily                                        1142\n",
      "HowStuffWorks                                     1141\n",
      "WCBE                                              1093\n",
      "Tech Xplore                                       1090\n",
      "KOSU                                              1086\n",
      "Daily Kos                                         1081\n",
      "The Daily Beast                                   1072\n",
      "Brookings                                         1070\n",
      "CNBC                                              1068\n",
      "WLRN                                              1059\n",
      "KUNM                                              1034\n",
      "Men's Health                                      1027\n",
      "Parent Herald                                     1015\n",
      "Elite Daily                                       1014\n",
      "Pressfrom                                         1007\n",
      "WUWM                                              1006\n",
      "MarketWatch                                       1000\n",
      "azfamily.com                                      994\n",
      "New Hampshire Public Radio                        992\n",
      "PR Web                                            978\n",
      "Counsel & Heal                                    974\n",
      "WBUR                                              947\n",
      "American Council on Science and Health            941\n",
      "Emaxhealth.com                                    940\n",
      "ABC News                                          934\n",
      "12 News KBMT                                      922\n",
      "Reason                                            915\n",
      "New York Daily News                               905\n",
      "The Seattle Times                                 902\n",
      "Pharmacy Times                                    886\n",
      "Women's Health                                    873\n",
      "SDPB Radio                                        849\n",
      "TCTMD                                             849\n",
      "KiiiTV 3                                          846\n",
      "Renal & Urology News                              833\n",
      "WABE                                              830\n",
      "Outside                                           823\n",
      "Discover Magazine                                 815\n",
      "Equities.com                                      812\n",
      "Health Imaging                                    793\n",
      "My Science                                        787\n",
      "Arizona Public Radio                              777\n",
      "KPCC : Southern California Public Radio           770\n",
      "KUNC                                              762\n",
      "She Knows                                         754\n",
      "Nutra Ingredients USA                             752\n",
      "The Week                                          734\n",
      "Buzzfeed                                          729\n",
      "SeedQuest                                         726\n",
      "Common Dreams                                     725\n",
      "Prevention                                        716\n",
      "Minyanville: Finance                              706\n",
      "Mother Jones                                      695\n",
      "The University of New Orleans Public Radio        688\n",
      "Central Coast Public Radio                        686\n",
      "Houston Chronicle                                 683\n",
      "The Verge                                         678\n",
      "Public Radio International                        673\n",
      "Inc.                                              667\n",
      "WRKF                                              667\n",
      "Value Walk                                        660\n",
      "The University Herald                             642\n",
      "Popular Mechanics                                 637\n",
      "Medcity News                                      637\n",
      "Witchita's Public Radio                           628\n",
      "WPTV 5 West Palm Beach                            617\n",
      "Interlochen Public Radio                          616\n",
      "ABC Action News WFTS Tampa Bay                    614\n",
      "Relief Web                                        613\n",
      "Cardiovascular Business                           608\n",
      "ABC News 15 Arizona                               599\n",
      "The Atlanta Journal Constitution                  591\n",
      "Astrobiology Magazine                             586\n",
      "WVXU                                              580\n",
      "Healthline                                        573\n",
      "Insurance News Net                                573\n",
      "St. Louis Post-Dispatch                           572\n",
      "Rocket News                                       560\n",
      "Bio-Medicine.org                                  553\n",
      "Northwest Indiana Times                           551\n",
      "Herald Sun                                        546\n",
      "The Columbian                                     529\n",
      "Green Car Congress                                527\n",
      "Herald Tribune                                    520\n",
      "KCENG12                                           517\n",
      "Inside Science                                    510\n",
      "Cornell Chronicle                                 509\n",
      "FiveThirtyEight                                   506\n",
      "AOL                                               495\n",
      "Health                                            488\n",
      "WTOP                                              481\n",
      "Lifehacker                                        479\n",
      "Alaska Despatch News                              472\n",
      "The San Diego Union-Tribune                       461\n",
      "Politico Magazine                                 454\n",
      "The Deseret News                                  451\n",
      "Springfield News Sun                              450\n",
      "Billings Gazette                                  444\n",
      "Government Executive                              437\n",
      "New York Magazine                                 429\n",
      "The Sacramento Bee                                425\n",
      "The Modesto Bee                                   420\n",
      "OnMedica                                          414\n",
      "Raleigh News and Observer                         408\n",
      "ABC 7 WKBW Buffalo                                408\n",
      "The Daily Caller                                  407\n",
      "Winona Daily News                                 405\n",
      "Dayton Daily News                                 387\n",
      "Star Tribune                                      380\n",
      "Pettinga: Stock Market                            371\n",
      "Lincoln Journal Star                              367\n",
      "KTEN                                              346\n",
      "Voice of America                                  339\n",
      "ABC News WMUR 9                                   335\n",
      "Lexington Herald Leader                           324\n",
      "The Charlotte Observer                            322\n",
      "Sun Herald                                        318\n",
      "The Ecologist                                     316\n",
      "The Body                                          314\n",
      "Popular Science                                   313\n",
      "The Wichita Eagle                                 310\n",
      "Kansas City Star                                  309\n",
      "Idaho Statements                                  308\n",
      "Mic                                               306\n",
      "News Tribune                                      298\n",
      "The Bellingham Herald                             295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Advocate                                      294\n",
      "The Fresno Bee                                    293\n",
      "PM 360                                            292\n",
      "Star-Telegram                                     288\n",
      "Radio Acadie                                      279\n",
      "Belleville News-Democrat                          276\n",
      "Statesman.com                                     273\n",
      "The Denver Post                                   264\n",
      "News Channel                                      241\n",
      "hellogiggles.com                                  231\n",
      "SFGate                                            227\n",
      "King 5                                            194\n",
      "The Daily Meal                                    191\n",
      "The New York Observer                             167\n",
      "KUOW                                              157\n",
      "Drug Discovery and Development                    129\n",
      "Hawaii News Now                                   120\n",
      "US News Health                                    101\n",
      "R&D                                               83\n"
     ]
    }
   ],
   "source": [
    "for target, val in combined_csv['Outlet or Author'].value_counts().items():\n",
    "    print('{:50}{:}'.format(target, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list(set(combined_csv['Mention URL'].tolist()))\n",
    "dois = list(set(combined_csv['DOI'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. of unique news articles: 520061\n",
      "num. of unique journal papers: 275403\n",
      "num. of mentions: 749029\n"
     ]
    }
   ],
   "source": [
    "print('num. of unique news articles: %d'%len(urls))\n",
    "print('num. of unique journal papers: %d'%len(dois))\n",
    "print('num. of mentions: %d'%len(combined_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_mentioned_paper_cn = defaultdict(int)\n",
    "\n",
    "for url, doi in combined_csv[['Mention URL', 'DOI']].itertuples(index=False, name=None):\n",
    "    url_mentioned_paper_cn[url] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WoS corresponding author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Different from MAG that includes each author-affiliation in the author list, WoS has a field indicating all affiliations. E.g., {\"_addr_no\": \"1 5\", \"_role\": \"author\", \"_seq_no\": 1} means that the first author has two affiliations: \"1\" and \"5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every doi in this dict has corresponding info.\n",
    "doi_wos_authors = {}\n",
    "\n",
    "with open(data_root+'doi_wos_authors.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        doi, authors = row['doi_lowercase'], row['authors']\n",
    "        # some are not of 'author' role.\n",
    "        authors = [aut for aut in authors if aut['_role'] == 'author']\n",
    "        ca_pos_list = []\n",
    "        aut_last_names = [''] * len(authors)\n",
    "        for aut in authors:\n",
    "            pos = aut['_seq_no']\n",
    "            if 'last_name' in aut:\n",
    "                aut_last_names[pos-1] = aut['last_name']\n",
    "            else:\n",
    "                aut_last_names[pos-1] = aut['full_name']\n",
    "            if '_reprint' in aut and aut['_reprint'] == 'Y':\n",
    "                ca_pos_list.append(pos)\n",
    "        doi_wos_authors[doi] = {'aut_last_names':aut_last_names, 'ca_pos_list': ca_pos_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aut_last_names': ['Bachen', 'Chesney', 'Criswell'], 'ca_pos_list': [1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi_wos_authors['10.1002/art.24519']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAG author names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we queried more dois than those papers mentioned by this US-outlets subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if an author has multiple affiliations, MAG codes the author list like this:\n",
    "\n",
    "[['1221368641', '79576946', '2', 'David F. Dinges'], ['2042375510', '79576946', '1', 'Mathias Basner'], ['2042375510', '2898391981', '1', 'Mathias Basner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# risk set\n",
    "doi_author_list = defaultdict(list)\n",
    "doi_num_authors = {}\n",
    "\n",
    "with open(data_root+'dois_authors_mag.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        doi, authors = row['doi'], row['authors']\n",
    "        uniq_authors = defaultdict(lambda: ['', [], ''])\n",
    "        for aid, affi_id, seq, name in authors:\n",
    "            seq = int(seq)\n",
    "            uniq_authors[seq][0] = aid\n",
    "            uniq_authors[seq][1].append(affi_id)\n",
    "            uniq_authors[seq][2] = unidecode.unidecode(name)\n",
    "        # could be [1, 2, 4, 6]; [2, 3]\n",
    "        uniq_seqs = sorted(uniq_authors)\n",
    "        # must be: 1, 2, ..., max\n",
    "        if uniq_seqs == list(range(1, len(uniq_seqs)+1)):\n",
    "            last_seq = len(uniq_seqs)\n",
    "            doi_num_authors[doi] = last_seq\n",
    "            if last_seq == 1:\n",
    "                aid, affi_ids, name = uniq_authors[last_seq]\n",
    "                affis = '|'.join(affi_ids)\n",
    "                doi_author_list[doi].append([aid, affis, last_seq, name, 'solo_author'])\n",
    "            else:\n",
    "                cor_pos = []\n",
    "                if doi in doi_wos_authors:\n",
    "                    # this is already unique seq\n",
    "                    cor_pos = doi_wos_authors[doi]['ca_pos_list']\n",
    "                for seq in uniq_authors:\n",
    "                    aid, affi_ids, name = uniq_authors[seq]\n",
    "                    affis = '|'.join(affi_ids)\n",
    "                    if seq == 1:\n",
    "                        doi_author_list[doi].append([aid, affis, seq, name, 'first_position'])\n",
    "                    elif seq == last_seq:\n",
    "                        doi_author_list[doi].append([aid, affis, seq, name, 'last_position'])\n",
    "                    elif seq in cor_pos:\n",
    "                        doi_author_list[doi].append([aid, affis, seq, name, 'middle_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268691"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doi_author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268691"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doi_num_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aid_metric = {}\n",
    "with open(data_root+'aids_metric_mag.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        aid, metric = row['aid'], row['metric']\n",
    "        aid_metric[aid] = [int(num) for num in metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each (url, doi, author) triplet is an observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the potential data points for the reg analysis since to know the dependent variable, one needs two info:\n",
    "* story text (in `urls_text`)\n",
    "* author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = combined_csv.loc[combined_csv['DOI'].isin(set(doi_author_list.keys()))]\n",
    "combined_csv.index = range(len(combined_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674272"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_to_doi_edges = list(combined_csv[['Mention URL', 'DOI']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674272"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_to_doi_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How data size changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_date = dict(zip(combined_csv.DOI, combined_csv['Publication Date']))\n",
    "urls_date = dict(zip(combined_csv['Mention URL'], combined_csv['Mention Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_journal = dict(zip(combined_csv.DOI, combined_csv['Journal/Collection Title']))\n",
    "urls_outlet = dict(zip(combined_csv['Mention URL'], combined_csv['Outlet or Author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_mention_cn = {doi: cn for doi, cn in combined_csv.DOI.value_counts().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 520061 stories mentioning 275403 dois.\n",
      "We found author info for 251630 dois in MAG, and they were mentioned by 472762 stories.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d stories mentioning %d dois.'%(len(urls_text), len(dois)))\n",
    "print('We found author info for %d dois in MAG, and they were mentioned by %d stories.'%(len(dois_date), len(urls_date)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manually categorize outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(combined_csv['Outlet or Author'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_cate = pd.read_csv(data_root+'outlet_category.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_cate = dict(zip(outlet_cate.outlet, outlet_cate.category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'General', 'PressRelease', 'SciTech'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(outlet_cate.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_cates = {\n",
    "    'PressRelease': 'Press Releases',\n",
    "    'SciTech': 'Sci. \\& Tech.',\n",
    "    'General': 'General News'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnMedica & Sci. \\& Tech. \\\\\n",
      "Huffington Post & General News \\\\\n",
      "KiiiTV 3 & General News \\\\\n",
      "Carbon Brief & Sci. \\& Tech. \\\\\n",
      "PR Newswire & Press Releases \\\\\n",
      "Nutra Ingredients USA & Sci. \\& Tech. \\\\\n",
      "The Bellingham Herald & General News \\\\\n",
      "CNN News & General News \\\\\n",
      "Health Medicinet & Press Releases \\\\\n",
      "Herald Sun & General News \\\\\n",
      "EurekAlert! & Press Releases \\\\\n",
      "AJMC & Press Releases \\\\\n",
      "The University Herald & General News \\\\\n",
      "Lincoln Journal Star & General News \\\\\n",
      "Cardiovascular Business & Sci. \\& Tech. \\\\\n",
      "MinnPost & General News \\\\\n",
      "CNET & Sci. \\& Tech. \\\\\n",
      "Infection Control Today & Sci. \\& Tech. \\\\\n",
      "Science 2.0 & Sci. \\& Tech. \\\\\n",
      "Lexington Herald Leader & General News \\\\\n",
      "Statesman.com & General News \\\\\n",
      "Nanowerk & Press Releases \\\\\n",
      "The San Diego Union-Tribune & General News \\\\\n",
      "The Daily Beast & General News \\\\\n",
      "Lab Manager & Press Releases \\\\\n",
      "SDPB Radio & General News \\\\\n",
      "New Hampshire Public Radio & General News \\\\\n",
      "Health Day & Press Releases \\\\\n",
      "Rocket News & General News \\\\\n",
      "KPBS & General News \\\\\n",
      "Technology.org & Press Releases \\\\\n",
      "UPI.com & General News \\\\\n",
      "WUWM & General News \\\\\n",
      "Central Coast Public Radio & General News \\\\\n",
      "The Hill & General News \\\\\n",
      "The Epoch Times & General News \\\\\n",
      "Biospace & Sci. \\& Tech. \\\\\n",
      "Minyanville: Finance & General News \\\\\n",
      "Nature World News & Sci. \\& Tech. \\\\\n",
      "New York Post & General News \\\\\n",
      "Action News Now & General News \\\\\n",
      "WUNC & General News \\\\\n",
      "Futurity & Press Releases \\\\\n",
      "Reason & General News \\\\\n",
      "azfamily.com & General News \\\\\n",
      "Idaho Statements & General News \\\\\n",
      "Google News & General News \\\\\n",
      "Tri States Public Radio & General News \\\\\n",
      "American Physical Society - Physics & Press Releases \\\\\n",
      "KTEP El Paso & General News \\\\\n",
      "LiveScience & Sci. \\& Tech. \\\\\n",
      "KUNC & General News \\\\\n",
      "The Daily Meal & Sci. \\& Tech. \\\\\n",
      "AOL & General News \\\\\n",
      "Women's Health & Sci. \\& Tech. \\\\\n",
      "Prevention & Sci. \\& Tech. \\\\\n",
      "ECN & Sci. \\& Tech. \\\\\n",
      "Iowa Public Radio & General News \\\\\n",
      "Becker's Hospital Review & Sci. \\& Tech. \\\\\n",
      "7th Space Family Portal & Press Releases \\\\\n",
      "Springfield News Sun & General News \\\\\n",
      "Environmental News Network & Press Releases \\\\\n",
      "Sky Nightly & Sci. \\& Tech. \\\\\n",
      "Quartz & Sci. \\& Tech. \\\\\n",
      "Benzinga & General News \\\\\n",
      "Headlines \\& Global News & General News \\\\\n",
      "The Denver Post & General News \\\\\n",
      "Science Daily & Press Releases \\\\\n",
      "The Advocate & General News \\\\\n",
      "ABC News & General News \\\\\n",
      "Newswise & Press Releases \\\\\n",
      "hellogiggles.com & General News \\\\\n",
      "WLRN & General News \\\\\n",
      "EarthSky & Sci. \\& Tech. \\\\\n",
      "Becker's Spine Review & Sci. \\& Tech. \\\\\n",
      "MIT News & Press Releases \\\\\n",
      "MarketWatch & General News \\\\\n",
      "Arstechnica & Sci. \\& Tech. \\\\\n",
      "Journalist's Resource & Sci. \\& Tech. \\\\\n",
      "Northern Public Radio & General News \\\\\n",
      "Everyday Health & Sci. \\& Tech. \\\\\n",
      "Star Tribune & General News \\\\\n",
      "TCTMD & Sci. \\& Tech. \\\\\n",
      "The Verge & General News \\\\\n",
      "She Knows & General News \\\\\n",
      "SeedQuest & Sci. \\& Tech. \\\\\n",
      "Tech Times & Sci. \\& Tech. \\\\\n",
      "Witchita's Public Radio & General News \\\\\n",
      "Oncology Nurse Advisor & Sci. \\& Tech. \\\\\n",
      "Delmarva Public Radio & General News \\\\\n",
      "Medical Daily & Sci. \\& Tech. \\\\\n",
      "Homeland Security News Wire & General News \\\\\n",
      "Discover Magazine & Sci. \\& Tech. \\\\\n",
      "Washington Post & General News \\\\\n",
      "MSN & General News \\\\\n",
      "Hawaii News Now & General News \\\\\n",
      "The Daily Caller & General News \\\\\n",
      "News Tribune & General News \\\\\n",
      "The Fresno Bee & General News \\\\\n",
      "King 5 & General News \\\\\n",
      "Star-Telegram & General News \\\\\n",
      "CNBC & General News \\\\\n",
      "Salon & General News \\\\\n",
      "WJCT & General News \\\\\n",
      "WVPE & General News \\\\\n",
      "KTEN & General News \\\\\n",
      "Wired.com & General News \\\\\n",
      "Daily Kos & General News \\\\\n",
      "USA Today & General News \\\\\n",
      "Men's Health & Sci. \\& Tech. \\\\\n",
      "Boise State Public Radio & General News \\\\\n",
      "Voice of America & General News \\\\\n",
      "PR Web & Press Releases \\\\\n",
      "Georgia Public Radio & General News \\\\\n",
      "FiveThirtyEight & General News \\\\\n",
      "Public Radio International & General News \\\\\n",
      "Harvard Business Review & General News \\\\\n",
      "Inverse & General News \\\\\n",
      "Doctors Lounge & Sci. \\& Tech. \\\\\n",
      "North East Public Radio & General News \\\\\n",
      "The Charlotte Observer & General News \\\\\n",
      "National Geographic & Sci. \\& Tech. \\\\\n",
      "Pharmacy Times & Sci. \\& Tech. \\\\\n",
      "Popular Science & Sci. \\& Tech. \\\\\n",
      "ABC Action News WFTS Tampa Bay & General News \\\\\n",
      "News Channel & General News \\\\\n",
      "The University of New Orleans Public Radio & General News \\\\\n",
      "Mic & General News \\\\\n",
      "Health Canal & Sci. \\& Tech. \\\\\n",
      "KOSU & General News \\\\\n",
      "Raleigh News and Observer & General News \\\\\n",
      "The Atlantic & General News \\\\\n",
      "newsmax.com & General News \\\\\n",
      "Yahoo! Finance USA & General News \\\\\n",
      "Government Executive & General News \\\\\n",
      "International Business Times & General News \\\\\n",
      "Emaxhealth.com & Press Releases \\\\\n",
      "Newsweek & General News \\\\\n",
      "FOX News & General News \\\\\n",
      "The New York Observer & General News \\\\\n",
      "Sign of the Times & General News \\\\\n",
      "The Inquisitr & General News \\\\\n",
      "ABC News 15 Arizona & General News \\\\\n",
      "Parent Herald & General News \\\\\n",
      "The ASCO Post & Sci. \\& Tech. \\\\\n",
      "Clinical Advisor & Sci. \\& Tech. \\\\\n",
      "Slate Magazine & General News \\\\\n",
      "NPR & General News \\\\\n",
      "Health & Sci. \\& Tech. \\\\\n",
      "Dayton Daily News & General News \\\\\n",
      "Guardian Liberty Voice & General News \\\\\n",
      "Belleville News-Democrat & General News \\\\\n",
      "Yahoo! News & General News \\\\\n",
      "WCBE & General News \\\\\n",
      "Buzzfeed & General News \\\\\n",
      "Sci-News & Sci. \\& Tech. \\\\\n",
      "The Seattle Times & General News \\\\\n",
      "Philly.com & General News \\\\\n",
      "Renal \\& Urology News & Sci. \\& Tech. \\\\\n",
      "Arizona Public Radio & General News \\\\\n",
      "Interlochen Public Radio & General News \\\\\n",
      "12 News KBMT & General News \\\\\n",
      "New York Magazine & General News \\\\\n",
      "Medium US & General News \\\\\n",
      "KPCC : Southern California Public Radio & General News \\\\\n",
      "2 Minute Medicine & Sci. \\& Tech. \\\\\n",
      "Pediatric News & Sci. \\& Tech. \\\\\n",
      "redOrbit & Sci. \\& Tech. \\\\\n",
      "Insurance News Net & General News \\\\\n",
      "Drug Discovery and Development & Sci. \\& Tech. \\\\\n",
      "USNews.com & General News \\\\\n",
      "Yahoo! & General News \\\\\n",
      "The Body & Sci. \\& Tech. \\\\\n",
      "GEN & Sci. \\& Tech. \\\\\n",
      "Pacific Standard & General News \\\\\n",
      "Northwest Indiana Times & General News \\\\\n",
      "Psychology Today & Sci. \\& Tech. \\\\\n",
      "Oregon Public Broadcasting & General News \\\\\n",
      "Mother Nature Network & Sci. \\& Tech. \\\\\n",
      "Pressfrom & General News \\\\\n",
      "Physician's Weekly & Sci. \\& Tech. \\\\\n",
      "Pettinga: Stock Market & General News \\\\\n",
      "Winona Daily News & General News \\\\\n",
      "Runner's World & Sci. \\& Tech. \\\\\n",
      "Bio-Medicine.org & Press Releases \\\\\n",
      "Alternet & General News \\\\\n",
      "Mother Jones & General News \\\\\n",
      "The Wichita Eagle & General News \\\\\n",
      "Cornell Chronicle & Press Releases \\\\\n",
      "Politico Magazine & General News \\\\\n",
      "Equities.com & General News \\\\\n",
      "WBUR & General News \\\\\n",
      "ABC 7 WKBW Buffalo & General News \\\\\n",
      "Billings Gazette & General News \\\\\n",
      "My Science & Sci. \\& Tech. \\\\\n",
      "The Week & General News \\\\\n",
      "BioTech Gate & Sci. \\& Tech. \\\\\n",
      "Kansas City Star & General News \\\\\n",
      "The Deseret News & General News \\\\\n",
      "PBS & General News \\\\\n",
      "Space.com & Sci. \\& Tech. \\\\\n",
      "Astrobiology Magazine & Sci. \\& Tech. \\\\\n",
      "Outside & General News \\\\\n",
      "Value Walk & General News \\\\\n",
      "WYPR & General News \\\\\n",
      "Bustle & General News \\\\\n",
      "Science World Report & Sci. \\& Tech. \\\\\n",
      "Inside Science & Sci. \\& Tech. \\\\\n",
      "Science Alert & Sci. \\& Tech. \\\\\n",
      "Breitbart News Network & General News \\\\\n",
      "St. Louis Post-Dispatch & General News \\\\\n",
      "HowStuffWorks & General News \\\\\n",
      "Wyoming Public Radio & General News \\\\\n",
      "UBM Medica & Sci. \\& Tech. \\\\\n",
      "Fight Aging! & Sci. \\& Tech. \\\\\n",
      "MIT Technology Review & Sci. \\& Tech. \\\\\n",
      "WVXU & General News \\\\\n",
      "The Ecologist & Sci. \\& Tech. \\\\\n",
      "Alaska Despatch News & General News \\\\\n",
      "Health Imaging & Sci. \\& Tech. \\\\\n",
      "Kansas City University Radio & General News \\\\\n",
      "Christian Science Monitor & General News \\\\\n",
      "Medicinenet & Sci. \\& Tech. \\\\\n",
      "WTOP & General News \\\\\n",
      "Business Insider & General News \\\\\n",
      "Real Clear Science & Sci. \\& Tech. \\\\\n",
      "Counsel \\& Heal & Sci. \\& Tech. \\\\\n",
      "The Raw Story & General News \\\\\n",
      "Medcity News & Sci. \\& Tech. \\\\\n",
      "Drugs.com & Sci. \\& Tech. \\\\\n",
      "Relief Web & Press Releases \\\\\n",
      "SPIE Newsroom & Sci. \\& Tech. \\\\\n",
      "New York Daily News & General News \\\\\n",
      "Newser & General News \\\\\n",
      "The Sacramento Bee & General News \\\\\n",
      "Vice & General News \\\\\n",
      "R\\&D & Sci. \\& Tech. \\\\\n",
      "KCENG12 & Sci. \\& Tech. \\\\\n",
      "Inc. & General News \\\\\n",
      "Science/AAAS & Sci. \\& Tech. \\\\\n",
      "The Atlanta Journal Constitution & General News \\\\\n",
      "Brookings & General News \\\\\n",
      "Common Dreams & General News \\\\\n",
      "Physician's Briefing & Press Releases \\\\\n",
      "KERA News & General News \\\\\n",
      "Space Daily & Sci. \\& Tech. \\\\\n",
      "Tech Xplore & Sci. \\& Tech. \\\\\n",
      "US News Health & Sci. \\& Tech. \\\\\n",
      "KUOW & General News \\\\\n",
      "WRKF & General News \\\\\n",
      "TIME Magazine & General News \\\\\n",
      "Smithsonian Magazine & Sci. \\& Tech. \\\\\n",
      "Herald Tribune & General News \\\\\n",
      "Lifehacker & General News \\\\\n",
      "Fast Company & General News \\\\\n",
      "Kansas Public Radio & General News \\\\\n",
      "Omaha Public Radio & General News \\\\\n",
      "New York Times & General News \\\\\n",
      "Technology Networks & Sci. \\& Tech. \\\\\n",
      "Elite Daily & General News \\\\\n",
      "Centre for Disease Research and Policy & Sci. \\& Tech. \\\\\n",
      "Business Wire & General News \\\\\n",
      "KUNM & General News \\\\\n",
      "CBS News & General News \\\\\n",
      "Scientific American & Sci. \\& Tech. \\\\\n",
      "NBC News & General News \\\\\n",
      "Sun Herald & General News \\\\\n",
      "KRWG TV/FM & General News \\\\\n",
      "TODAY & General News \\\\\n",
      "Radio Acadie & General News \\\\\n",
      "The Columbian & General News \\\\\n",
      "Houston Chronicle & General News \\\\\n",
      "WABE & General News \\\\\n",
      "The Modesto Bee & General News \\\\\n",
      "American Council on Science and Health & Sci. \\& Tech. \\\\\n",
      "WKAR & General News \\\\\n",
      "Psych Central & Sci. \\& Tech. \\\\\n",
      "WebMD News & Sci. \\& Tech. \\\\\n",
      "Green Car Congress & Sci. \\& Tech. \\\\\n",
      "ABC News WMUR 9 & General News \\\\\n",
      "Healthline & Sci. \\& Tech. \\\\\n",
      "Mongabay & Sci. \\& Tech. \\\\\n",
      "Vox.com & General News \\\\\n",
      "WPTV 5 West Palm Beach & General News \\\\\n",
      "Popular Mechanics & Sci. \\& Tech. \\\\\n",
      "PM 360 & Sci. \\& Tech. \\\\\n",
      "SFGate & General News \\\\\n",
      "Seed Daily & Sci. \\& Tech. \\\\\n"
     ]
    }
   ],
   "source": [
    "for outlet, cate in outlet_cate.items():\n",
    "    outlet = outlet.replace('&', '\\&')\n",
    "    print('%s & %s \\\\\\\\'%(outlet, re_cates[cate]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare reg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = []\n",
    "for url, doi in url_to_doi_edges:\n",
    "    for aid, affis, seq, name, pos in doi_author_list[doi]:\n",
    "        reg_data.append([url, doi, aid, affis, seq, name, pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = pd.DataFrame(reg_data, columns=['url', 'doi', 'author_id', 'affiliation_ids', 'author_seq_num', 'author_name', 'author_pos_cate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353498"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del url_to_doi_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ethnicity and gender (authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential errors due to unknown: http://abel.lis.illinois.edu/cgi-bin/ethnea/search.py?Fname=Daniel&Lname=Schwartz\n",
    "eth_url = 'http://abel.lis.illinois.edu/cgi-bin/ethnea/search.py?format=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Genni': 'F', 'Ethnea': 'ENGLISH', 'Last': 'McDowell', 'First': 'C Anna'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {'Fname': 'C. Anna', 'Lname': 'McDowell'}\n",
    "response = requests.get(eth_url, params=payload)\n",
    "eval(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1000 names...\n",
      "processed 2000 names...\n",
      "processed 3000 names...\n",
      "processed 4000 names...\n",
      "processed 5000 names...\n",
      "processed 6000 names...\n",
      "processed 7000 names...\n",
      "processed 8000 names...\n",
      "processed 9000 names...\n",
      "processed 10000 names...\n"
     ]
    }
   ],
   "source": [
    "cn = 0\n",
    "for name in set(reg_data.author_name):\n",
    "    if name not in nname_eth_gen:\n",
    "        cn += 1\n",
    "        payload = get_author_name(name)\n",
    "        if payload != 'invalid':\n",
    "            if cn%500 == 0:\n",
    "                time.sleep(5)\n",
    "            response = requests.get(eth_url, params=payload)\n",
    "            try:\n",
    "                j = eval(response.text)\n",
    "                genni = j['Genni']\n",
    "                ethnea = j['Ethnea']\n",
    "                nname_eth_gen[name] = {'Ethnea': ethnea, 'Genni': genni}\n",
    "            except:\n",
    "                continue\n",
    "        if cn%1000 == 0:\n",
    "            print('processed %d names...'%cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_root+'nname_eth_gen.json', 'w') as ofile:\n",
    "#     for name, info in nname_eth_gen.items():\n",
    "#         row = {'name': name, 'info': info}\n",
    "#         ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nname_eth_gen = {}\n",
    "with open(data_root+'nname_eth_gen.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        name, info = row['name'], row['info']\n",
    "        nname_eth_gen[name] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351549"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nname_eth_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ethnicity and gender (reporters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize names\n",
    "url_reporter = {}\n",
    "\n",
    "with open(data_root+'crawl_news/url_reporter.json', 'r') as ifile:\n",
    "    for row in ifile:\n",
    "        row = json.loads(row)\n",
    "        url, reporter = row['url'], row['reporter']\n",
    "        url_reporter[url] = unidecode.unidecode(reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100163"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_norm_names = set(url_reporter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13693"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reporter_norm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_eth_gen = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, name in enumerate(reporter_norm_names):\n",
    "    payload = get_author_name(name)\n",
    "    if payload != 'invalid':\n",
    "        if ix%200 == 0:\n",
    "            time.sleep(5)\n",
    "        response = requests.get(eth_url, params=payload)\n",
    "        try:\n",
    "            j = eval(response.text)\n",
    "            genni = j['Genni']\n",
    "            ethnea = j['Ethnea']\n",
    "            reporter_eth_gen[name] = {'Ethnea': ethnea, 'Genni': genni}\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_root+'crawl_news/reporter_eth_gen.json', 'w') as ofile:\n",
    "#     for name, info in reporter_eth_gen.items():\n",
    "#         row = {'name': name, 'info': info}\n",
    "#         ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_eth_gen = {}\n",
    "\n",
    "with open(data_root+'crawl_news/reporter_eth_gen.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        name, info = row['name'], row['info']\n",
    "        reporter_eth_gen[name] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13632"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reporter_eth_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict ethnicity using Wiki/Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_name(name, pos = 'first'):\n",
    "    payload = get_author_name(name)\n",
    "    if payload != 'invalid':\n",
    "        if pos == 'first':\n",
    "            return payload['Fname']\n",
    "        if pos == 'last':\n",
    "            return payload['Lname']\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = pd.DataFrame(set(reg_data.author_name.tolist()).union(reporter_norm_names), columns=['nname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df['Fname'] = name_df.nname.apply(lambda name: get_pos_name(name, pos='first'))\n",
    "name_df['Lname'] = name_df.nname.apply(lambda name: get_pos_name(name, pos='last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nname</th>\n",
       "      <th>Fname</th>\n",
       "      <th>Lname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At Bulathsinghala</td>\n",
       "      <td>At</td>\n",
       "      <td>Bulathsinghala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaushik Mukherjee</td>\n",
       "      <td>Kaushik</td>\n",
       "      <td>Mukherjee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sophie Fisher</td>\n",
       "      <td>Sophie</td>\n",
       "      <td>Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rostyslaw W. Robak</td>\n",
       "      <td>Rostyslaw</td>\n",
       "      <td>Robak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Vickery</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Vickery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                nname      Fname           Lname\n",
       "0   At Bulathsinghala         At  Bulathsinghala\n",
       "1   Kaushik Mukherjee    Kaushik       Mukherjee\n",
       "2       Sophie Fisher     Sophie          Fisher\n",
       "3  Rostyslaw W. Robak  Rostyslaw           Robak\n",
       "4  Richard M. Vickery    Richard         Vickery"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use other server to do the next line of code.\n",
    "name_df.to_csv(data_root+'name_df.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df_wiki = pred_wiki_name(df=name_df, lname_col='Lname', fname_col='Fname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df_wiki = pd.read_csv(data_root+'name_df_wiki.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_eth_wiki = dict(zip(name_df_wiki.nname, name_df_wiki.race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_eth_wiki['solo'] = 'solo'\n",
    "name_eth_wiki['unknown'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_df_census = pred_census_ln(df=name_df, namecol='Lname', year=2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df_census = pd.read_csv(data_root+'name_df_census.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nname</th>\n",
       "      <th>Fname</th>\n",
       "      <th>Lname</th>\n",
       "      <th>race</th>\n",
       "      <th>api</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At Bulathsinghala</td>\n",
       "      <td>At</td>\n",
       "      <td>Bulathsinghala</td>\n",
       "      <td>white</td>\n",
       "      <td>0.124314</td>\n",
       "      <td>0.02164</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>0.843221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nname Fname           Lname   race       api    black  \\\n",
       "0  At Bulathsinghala    At  Bulathsinghala  white  0.124314  0.02164   \n",
       "\n",
       "   hispanic     white  \n",
       "0  0.010825  0.843221  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df_census.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_eth_census = dict(zip(name_df_census.nname, name_df_census.race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_eth_census['solo'] = 'solo'\n",
    "name_eth_census['unknown'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del name_df_wiki, name_df_census, name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /shared/0/projects/news-quotes/Affiliations.txt...\n"
     ]
    }
   ],
   "source": [
    "# Queen's College, London -> queen s college london\n",
    "# McKinsey & Company -> mckinsey company\n",
    "# https://docs.microsoft.com/en-us/academic-services/graph/reference-data-schema\n",
    "# Rank = -1000 * Ln( probability of an entity being important )\n",
    "affi_rank = {}\n",
    "affi_country = {}\n",
    "affi_name = {}\n",
    "for line in yield_one_line('Affiliations.txt'):\n",
    "    affi_id, rank, dname, lat, lon = line[0], line[1], line[3], line[9], line[10]\n",
    "    affi_rank[affi_id] = int(rank)\n",
    "    affi_name[affi_id] = dname\n",
    "    if lat != \"\" and lon != \"\":\n",
    "        lat, lon = float(lat), float(lon)\n",
    "        res = reverse_geocode.search([(lat, lon)])\n",
    "        country = res[0]['country']\n",
    "        affi_country[affi_id] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25542"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(affi_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(affi_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25542"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(affi_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /shared/0/projects/news-quotes/wos_jcr.csv...\n"
     ]
    }
   ],
   "source": [
    "# Altmetric data: JAMA: Journal of the American Medical Association\n",
    "# WOS data: JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION\n",
    "journal_impact = {}\n",
    "for line in yield_one_line('wos_jcr.csv', delimiter=',', quote=csv.QUOTE_ALL):\n",
    "    rank, title, cites, jif, eigen = line\n",
    "    try:\n",
    "        impact = float(jif)\n",
    "        ntitle = norm_string(title)\n",
    "        journal_impact[ntitle] = impact\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11873"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(journal_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.273"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_impact['jama journal of the american medical association']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /shared/0/projects/news-quotes/Names_2010Census.csv...\n"
     ]
    }
   ],
   "source": [
    "# https://www2.census.gov/geo/tiger/TIGER1999/readme99.txt\n",
    "# DIACRITICAL MARKS\n",
    "\n",
    "# The Census Bureau is no longer using codes to represent diacritical marks found\n",
    "# in some language names.  Beginning with this release of TIGER/Line the Census\n",
    "# Bureau will be using the ISO 8859-1 character set, commonly referred to as Latin-1,\n",
    "# to identify characters with diacritical marks.\n",
    "\n",
    "family_freq = {}\n",
    "for line in yield_one_line('Names_2010Census.csv', delimiter=',', quote=csv.QUOTE_ALL):\n",
    "    name, rank, count, prop100k = line[:4]\n",
    "    if name != 'name':\n",
    "        family_freq[name] = np.log(float(prop100k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare reg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['author_last_name'] = reg_data['author_name'].apply(lambda name: name.split()[-1])\n",
    "reg_data['author_last_name'] = reg_data['author_last_name'].apply(lambda name: last_name_fix[name] if name in last_name_fix else name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['last_name_feats'] = reg_data['author_name'].apply(get_last_name_feats)\n",
    "reg_data[['last_name_length', 'last_name_prob']] = pd.DataFrame(reg_data['last_name_feats'].values.tolist(), index = reg_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['author_eth_gen'] = reg_data['author_name'].apply(lambda name: get_author_eth_gen(name))\n",
    "reg_data[['author_eth_ethnea', 'author_gender_ethnea']] = pd.DataFrame(reg_data['author_eth_gen'].values.tolist(), index = reg_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map wiki and census ethnicity\n",
    "reg_data['author_eth_wiki'] = reg_data.author_name.map(name_eth_wiki)\n",
    "reg_data['author_eth_census'] = reg_data.author_name.map(name_eth_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['reporter_name'] = reg_data['url'].apply(lambda url: url_reporter[url] if url in url_reporter else 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['reporter_eth_gen'] = reg_data['reporter_name'].apply(lambda name: get_reporter_eth_gen(name))\n",
    "reg_data[['reporter_eth_ethnea', 'reporter_gender_ethnea']] = pd.DataFrame(reg_data['reporter_eth_gen'].values.tolist(), index = reg_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map wiki and census ethnicity\n",
    "reg_data['reporter_eth_wiki'] = reg_data.reporter_name.map(name_eth_wiki)\n",
    "reg_data['reporter_eth_census'] = reg_data.reporter_name.map(name_eth_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = reg_data.drop(columns=['last_name_feats', 'author_eth_gen', 'reporter_eth_gen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ethnicity categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_cat_map = {\n",
    " 'ISRAELI': 'MiddleEastern',\n",
    " 'ARAB': 'MiddleEastern',\n",
    " 'TURKISH': 'MiddleEastern',\n",
    " 'ENGLISH': 'English',\n",
    " 'HISPANIC': 'SouthernEuropean',\n",
    " 'ITALIAN': 'SouthernEuropean',    \n",
    " 'GREEK': 'SouthernEuropean',\n",
    " 'GERMAN': 'WesternNorthernEuropean',\n",
    " 'NORDIC': 'WesternNorthernEuropean',\n",
    " 'DUTCH': 'WesternNorthernEuropean',\n",
    " 'FRENCH': 'WesternNorthernEuropean',\n",
    " 'BALTIC': 'WesternNorthernEuropean',\n",
    " 'HUNGARIAN': 'EasternEuropean',\n",
    " 'ROMANIAN': 'EasternEuropean',\n",
    " 'SLAV': 'EasternEuropean',\n",
    " 'CHINESE': 'Chinese',\n",
    " 'INDIAN': 'Indian',\n",
    " 'AFRICAN': 'African',\n",
    " 'KOREAN': 'EastAsian',\n",
    " 'JAPANESE': 'EastAsian',\n",
    " 'THAI': 'EastAsian',\n",
    " 'VIETNAMESE': 'EastAsian',\n",
    " 'INDONESIAN': 'EastAsian',\n",
    " 'MONGOLIAN': 'EastAsian',\n",
    " 'CARIBBEAN': 'CARIBBEAN',\n",
    " 'POLYNESIAN': 'POLYNESIAN',\n",
    " 'org': 'org',\n",
    " 'unknown': 'unknown'}\n",
    "# eastern europe: hungarian, slav, romanian\n",
    "# western and northern europe: baltic, dutch, german, nordic, french\n",
    "# south europe: hispanic, italian, greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_cat_map = {\n",
    " 'Asian,GreaterEastAsian,EastAsian': 'EastAsian',\n",
    " 'Asian,GreaterEastAsian,Japanese': 'EastAsian',\n",
    " 'Asian,IndianSubContinent': 'Indian',\n",
    " 'GreaterAfrican,Africans': 'African',\n",
    " 'GreaterAfrican,Muslim': 'MiddleEastern',\n",
    " 'GreaterEuropean,British': 'English',\n",
    " 'GreaterEuropean,EastEuropean': 'EasternEuropean',\n",
    " 'GreaterEuropean,Jewish': 'MiddleEastern',\n",
    " 'GreaterEuropean,WestEuropean,French': 'WesternNorthernEuropean',\n",
    " 'GreaterEuropean,WestEuropean,Germanic': 'WesternNorthernEuropean',\n",
    " 'GreaterEuropean,WestEuropean,Hispanic': 'SouthernEuropean',\n",
    " 'GreaterEuropean,WestEuropean,Italian': 'SouthernEuropean',\n",
    " 'GreaterEuropean,WestEuropean,Nordic': 'WesternNorthernEuropean',\n",
    "#  'solo': 'solo',\n",
    " 'unknown': 'unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map individual eth in `Ethnea` to higher-level categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['author_eth_ethnea_broad'] = reg_data['author_eth_ethnea'].map(eth_cat_map)\n",
    "reg_data['reporter_eth_ethnea_broad'] = reg_data['reporter_eth_ethnea'].map(eth_cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_eth_ethnea_broad\n",
       "English                    0.441768\n",
       "WesternNorthernEuropean    0.204497\n",
       "SouthernEuropean           0.104017\n",
       "Chinese                    0.078783\n",
       "MiddleEastern              0.048845\n",
       "Indian                     0.041041\n",
       "EastAsian                  0.036496\n",
       "EasternEuropean            0.034164\n",
       "African                    0.005327\n",
       "unknown                    0.004926\n",
       "CARIBBEAN                  0.000129\n",
       "org                        0.000004\n",
       "POLYNESIAN                 0.000001\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report this in SI - the distribution of eth before dropping data.\n",
    "reg_data.author_eth_ethnea_broad.value_counts() / len(reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_eth_ethnea_broad\n",
       "English                    594396\n",
       "WesternNorthernEuropean    275149\n",
       "SouthernEuropean           139954\n",
       "Chinese                    106002\n",
       "MiddleEastern               65720\n",
       "Indian                      55221\n",
       "EastAsian                   49105\n",
       "EasternEuropean             45968\n",
       "African                      7168\n",
       "unknown                      6628\n",
       "CARIBBEAN                     174\n",
       "org                             6\n",
       "POLYNESIAN                      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report this in SI - the distribution of eth before dropping data.\n",
    "reg_data.author_eth_ethnea_broad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4418279490764589,\n",
       " 0.20452445568348138,\n",
       " 0.10403096384404796,\n",
       " 0.07879367670375102,\n",
       " 0.04885115783636646,\n",
       " 0.04104701440782094,\n",
       " 0.03650085370594606,\n",
       " 0.03416905087373849,\n",
       " 0.005328136022079653,\n",
       " 0.0049267418463091435]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f_exp\n",
    "(reg_data.author_eth_ethnea_broad.value_counts() / (len(reg_data) - 174 - 6 - 2)).tolist()[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345311"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(reg_data) - 174 - 6 - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map individual eth in `Wiki` to higher-level categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['author_eth_wiki_broad'] = reg_data['author_eth_wiki'].map(wiki_cat_map)\n",
    "reg_data['reporter_eth_wiki_broad'] = reg_data['reporter_eth_wiki'].map(wiki_cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_eth_ethnea</th>\n",
       "      <th>author_eth_wiki</th>\n",
       "      <th>author_eth_census</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1096/fj.14-255240</td>\n",
       "      <td>http://www.eurekalert.org/pub_releases/2014-10...</td>\n",
       "      <td>David B. Dunger</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1096/fj.14-255240</td>\n",
       "      <td>http://www.sciencedaily.com/releases/2014/10/1...</td>\n",
       "      <td>David B. Dunger</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuron.2013.08.030</td>\n",
       "      <td>http://www.sciencedaily.com/releases/2013/11/1...</td>\n",
       "      <td>Roshan Cools</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.neuron.2013.08.030</td>\n",
       "      <td>http://www.sciencedaily.com/releases/2013/11/1...</td>\n",
       "      <td>Hanneke E.M. den Ouden</td>\n",
       "      <td>DUTCH</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.rhm.2016.10.003</td>\n",
       "      <td>http://healthmedicinet.com/news/why-more-and-m...</td>\n",
       "      <td>Karen Lorimer</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doi  \\\n",
       "0          10.1096/fj.14-255240   \n",
       "1          10.1096/fj.14-255240   \n",
       "2  10.1016/j.neuron.2013.08.030   \n",
       "3  10.1016/j.neuron.2013.08.030   \n",
       "4     10.1016/j.rhm.2016.10.003   \n",
       "\n",
       "                                                 url             author_name  \\\n",
       "0  http://www.eurekalert.org/pub_releases/2014-10...         David B. Dunger   \n",
       "1  http://www.sciencedaily.com/releases/2014/10/1...         David B. Dunger   \n",
       "2  http://www.sciencedaily.com/releases/2013/11/1...            Roshan Cools   \n",
       "3  http://www.sciencedaily.com/releases/2013/11/1...  Hanneke E.M. den Ouden   \n",
       "4  http://healthmedicinet.com/news/why-more-and-m...           Karen Lorimer   \n",
       "\n",
       "  author_eth_ethnea          author_eth_wiki author_eth_census  \n",
       "0           ENGLISH  GreaterEuropean,British             white  \n",
       "1           ENGLISH  GreaterEuropean,British             white  \n",
       "2             DUTCH  GreaterEuropean,British             white  \n",
       "3             DUTCH  GreaterEuropean,British             white  \n",
       "4           ENGLISH  GreaterEuropean,British             white  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data[['doi', 'url', 'author_name', 'author_eth_ethnea', 'author_eth_wiki', 'author_eth_census']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg_data['Publication Date'] = reg_data['doi'].apply(lambda doi: dois_date[doi])\n",
    "reg_data['Mention Date'] = reg_data['url'].apply(lambda url: urls_date[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num of news coverage per paper\n",
    "reg_data['doi_men_cn'] = reg_data['doi'].map(doi_mention_cn)\n",
    "reg_data['author_rank'] = reg_data['author_id'].apply(get_author_rank)\n",
    "reg_data['affiliation_name'] = reg_data['affiliation_ids'].apply(get_affi_name)\n",
    "reg_data['affiliation_cate'] = reg_data['affiliation_ids'].apply(get_affi_cate)\n",
    "reg_data['affiliation_rank'] = reg_data['affiliation_ids'].apply(get_affi_rank)\n",
    "reg_data['journal_title'] = reg_data['doi'].apply(lambda doi: dois_journal[doi] if dois_journal[doi] != '' else 'unknown')\n",
    "reg_data['journal_impact'] = reg_data['journal_title'].apply(get_journal_rank)\n",
    "top_journals = set([jname for jname, num in Counter(reg_data['journal_title']).most_common()[:100] if jname != 'unknown'])\n",
    "reg_data['top_journal'] = reg_data['journal_title'].apply(get_journal_cate)\n",
    "reg_data['num_authors'] = reg_data['doi'].map(doi_num_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['outlet'] = reg_data['url'].map(urls_outlet)\n",
    "# e.g., 'Harvard Business Review ' was changed to 'Harvard Business Review' in the outlet categorization.\n",
    "reg_data['outlet'] = reg_data['outlet'].apply(lambda name: name.strip())\n",
    "reg_data['category'] = reg_data['outlet'].map(outlet_cate)\n",
    "reg_data['num_words'] = reg_data['url'].apply(get_news_length)\n",
    "reg_data['num_mentioned_papers'] = reg_data['url'].map(url_mentioned_paper_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['mention_year'] = reg_data['url'].apply(lambda url: int(urls_date[url][:4]))\n",
    "year_mean = reg_data['mention_year'].mean()\n",
    "reg_data['gap_in_years'] = reg_data.apply(get_year_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['is_author_mentioned'] = reg_data.apply(lambda row: check_aut_mentioned(row), axis=1)\n",
    "reg_data['is_author_mentioned'] = reg_data['is_author_mentioned'].apply(get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353498"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get readability stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_csv(data_root+'dois_abstract_readability_stats.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = read_df[['doi', 'FleschReadingEase', 'sentences_per_paragraph', 'type_token_ratio']]\n",
    "read_df = read_df.dropna()\n",
    "read_df.index = range(len(read_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156679"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_data = pd.merge(reg_data, read_df, how='left', on='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353498"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get final data for regression (drop missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                             0\n",
       "doi                             0\n",
       "author_id                       0\n",
       "affiliation_ids                 0\n",
       "author_seq_num                  0\n",
       "author_name                     0\n",
       "author_pos_cate                 0\n",
       "author_last_name                0\n",
       "last_name_length                0\n",
       "last_name_prob                  0\n",
       "author_eth_ethnea               0\n",
       "author_gender_ethnea            0\n",
       "author_eth_wiki                 0\n",
       "author_eth_census               0\n",
       "reporter_name                   0\n",
       "reporter_eth_ethnea             0\n",
       "reporter_gender_ethnea          0\n",
       "reporter_eth_wiki               0\n",
       "reporter_eth_census             0\n",
       "Publication Date                0\n",
       "Mention Date                    0\n",
       "doi_men_cn                      0\n",
       "author_rank                     0\n",
       "affiliation_name                0\n",
       "affiliation_cate                0\n",
       "affiliation_rank           370716\n",
       "journal_title                   0\n",
       "journal_impact             306573\n",
       "top_journal                     0\n",
       "num_authors                     0\n",
       "outlet                          0\n",
       "category                        0\n",
       "num_words                       0\n",
       "num_mentioned_papers            0\n",
       "mention_year                    0\n",
       "gap_in_years               178316\n",
       "is_author_mentioned             0\n",
       "FleschReadingEase          550758\n",
       "sentences_per_paragraph    550758\n",
       "type_token_ratio           550758\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(reg_data.isnull(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only these cols have missing values.\n",
    "reg_data = reg_data.dropna(subset=['affiliation_rank', 'gap_in_years', 'FleschReadingEase', 'sentences_per_paragraph', 'type_token_ratio'])\n",
    "reg_data.index = range(len(reg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping single char last name or He/She with no proper prefix.\n",
    "reg_data = reg_data.loc[reg_data['is_author_mentioned'] != 'drop']\n",
    "reg_data = reg_data.astype({\"is_author_mentioned\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENGLISH       234513\n",
       "GERMAN         47767\n",
       "CHINESE        43039\n",
       "HISPANIC       28808\n",
       "FRENCH         25232\n",
       "INDIAN         21314\n",
       "NORDIC         19697\n",
       "ITALIAN        17992\n",
       "SLAV           14830\n",
       "ARAB           14099\n",
       "DUTCH          13461\n",
       "JAPANESE       10838\n",
       "ISRAELI         9064\n",
       "KOREAN          7312\n",
       "GREEK           4334\n",
       "TURKISH         2919\n",
       "AFRICAN         2774\n",
       "unknown         2549\n",
       "HUNGARIAN       1731\n",
       "ROMANIAN         690\n",
       "THAI             657\n",
       "BALTIC           174\n",
       "VIETNAMESE       174\n",
       "CARIBBEAN         82\n",
       "INDONESIAN        81\n",
       "MONGOLIAN          6\n",
       "org                1\n",
       "Name: author_eth_ethnea, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.author_eth_ethnea.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_eth = [eth for eth, cn in reg_data.author_eth_ethnea_broad.value_counts().items() if cn > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English',\n",
       " 'Western&NorthernEuropean',\n",
       " 'SouthernEuropean',\n",
       " 'Chinese',\n",
       " 'MiddleEastern',\n",
       " 'Indian',\n",
       " 'EastAsian',\n",
       " 'EasternEuropean',\n",
       " 'African',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = reg_data.loc[reg_data['author_eth_ethnea_broad'].isin(top_eth) & reg_data['reporter_eth_ethnea_broad'].isin(top_eth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.index = range(len(reg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English                     234510\n",
       "Western&NorthernEuropean    106331\n",
       "SouthernEuropean             51134\n",
       "Chinese                      43039\n",
       "MiddleEastern                26082\n",
       "Indian                       21314\n",
       "EastAsian                    19068\n",
       "EasternEuropean              17251\n",
       "African                       2774\n",
       "unknown                       2549\n",
       "Name: author_eth_ethnea_broad, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.author_eth_ethnea_broad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                     418187\n",
       "English                      68652\n",
       "Western&NorthernEuropean     13790\n",
       "SouthernEuropean             10594\n",
       "MiddleEastern                 3494\n",
       "EasternEuropean               2924\n",
       "Chinese                       2449\n",
       "Indian                        2409\n",
       "EastAsian                      910\n",
       "African                        643\n",
       "Name: reporter_eth_ethnea_broad, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.reporter_eth_ethnea_broad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['mention_year_center'] = reg_data['mention_year'].apply(lambda x: x - year_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524052"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41243235404120204"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reg_data.is_author_mentioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African 0.29776496034607064\n",
      "Chinese 0.42092056042194287\n",
      "EastAsian 0.4062827774281519\n",
      "EasternEuropean 0.4580604022955191\n",
      "English 0.40909982516737026\n",
      "Indian 0.4358168340058178\n",
      "MiddleEastern 0.43125527183498197\n",
      "SouthernEuropean 0.406246333163844\n",
      "Western&NorthernEuropean 0.4082816864319907\n",
      "unknown 0.3468026677128286\n"
     ]
    }
   ],
   "source": [
    "for eth, gp in reg_data.groupby('author_eth_ethnea_broad'):\n",
    "    print(eth, np.mean(gp.is_author_mentioned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add corresponding author variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['is_corresponding'] = reg_data.apply(lambda row: is_correspond_author(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reg_data[['doi', 'author_name', 'author_pos_cate', 'is_corresponding']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87567"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[test['author_pos_cate'] == 'first_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84708"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that the first/last author of a doi may be dropped due to missing data but the paper may not be dropped.\n",
    "len(test.loc[test['author_pos_cate'] == 'last_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9169"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[test['author_pos_cate'] == 'middle_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[test['author_pos_cate'] == 'solo_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(reg_data['doi']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100486"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique papers\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8598809784447585"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the frac of paper that has CA in WoS, in the final regression data.\n",
    "np.sum(test.doi.isin(doi_wos_authors))/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['wos_correspond_pos'] = test['doi'].apply(lambda doi: doi_wos_authors[doi]['ca_pos_list'] if doi in doi_wos_authors else [])\n",
    "test['num_authors'] = test.doi.map(doi_num_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>wos_correspond_pos</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1096/fj.14-255240</td>\n",
       "      <td>[1]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.neuron.2013.08.030</td>\n",
       "      <td>[1]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.rhm.2016.10.003</td>\n",
       "      <td>[1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1177/0963721411408883</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1016/j.neuron.2013.08.003</td>\n",
       "      <td>[8]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             doi wos_correspond_pos  num_authors\n",
       "0           10.1096/fj.14-255240                [1]           12\n",
       "2   10.1016/j.neuron.2013.08.030                [1]            8\n",
       "4      10.1016/j.rhm.2016.10.003                [1]            5\n",
       "6       10.1177/0963721411408883                [2]            2\n",
       "10  10.1016/j.neuron.2013.08.003                [8]            9"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = [name for name, cn in reg_data[['doi', 'author_name']].drop_duplicates().author_name.value_counts().nlargest(100).items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['is_top_author'] = reg_data['author_name'].apply(lambda name: 'yes' if name in top_authors else 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for now to get the quote/indirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_data.to_csv(data_root+\"reg_data_plot.csv\", index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add quote/indirect dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_df = pd.read_csv(data_root+\"crawl_news/has_author_quotes.tsv\", sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'has_author_quote'], dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524052"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.insert(0, 'has_author_quote', tem_df['has_author_quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_df = pd.read_csv(data_root+\"crawl_news/has_indirect_quote.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'has_indirect_mention', 'mentions_author_institution'], dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.insert(0, 'mentions_author_institution', tem_df['mentions_author_institution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.insert(0, 'has_indirect_mention', tem_df['has_indirect_mention'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_dir = '/shared/0/datasets/mag/raw_data/'\n",
    "\n",
    "def yield_one_line_mag(filename, delimiter=',', quoting = csv.QUOTE_ALL):\n",
    "    '''a generator which produce one line of a given file'''\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter=delimiter, quoting=quoting)\n",
    "        count = 0\n",
    "        for row in reader:\n",
    "            count += 1\n",
    "            if count % 10000000 == 0:\n",
    "                print('processed %d lines...' % (count))\n",
    "            yield row\n",
    "\n",
    "def get_field_vector(doi):\n",
    "    vec = [0] * len(top_fields)\n",
    "    if doi in dois_disc:\n",
    "        for field, score in dois_disc[doi]:\n",
    "            if field in field_ix:\n",
    "                vec[field_ix[field]] = score\n",
    "    return vec\n",
    "\n",
    "def clean_field_name(name):\n",
    "    if name == 'Spin-Â½':\n",
    "        return 'Spin_half'\n",
    "    ans = ''\n",
    "    for ch in name:\n",
    "        if ch in ['(', ')', '-', ' ', \"'\"]:\n",
    "            ans += '_'\n",
    "        else:\n",
    "            ans += ch\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_id2name_level = dict()\n",
    "for line in yield_one_line_mag(mag_dir+'FieldsOfStudy.txt', delimiter='\\t', quoting=csv.QUOTE_NONE):\n",
    "    fid, rank, nname, dname, mtype, level, pc, cc, cdate = line\n",
    "    field_id2name_level[fid] = (dname, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_disc = {}\n",
    "with open(data_root+'dois_fields_mag.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        fields = row['fields']\n",
    "        doi = row['doi']\n",
    "        dois_disc[doi] = fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2780320433', 0.526666343],\n",
       " ['2779668308', 0.6762392],\n",
       " ['2780221984', 0.5918762],\n",
       " ['511355011', 0.544381559],\n",
       " ['2777391703', 0.6243656],\n",
       " ['555293320', 0.591008365],\n",
       " ['2910068830', 0.600785553],\n",
       " ['141071460', 0.387458026],\n",
       " ['2777180221', 0.6201425],\n",
       " ['71924100', 0.410550684]]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dois_disc['10.1001/2012.jama.11132']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_cn = defaultdict(int)\n",
    "top_fields = []\n",
    "\n",
    "cn_not = 0\n",
    "for doi in set(reg_data.doi.to_list()):\n",
    "    if doi in dois_disc:\n",
    "        fields = dois_disc[doi]\n",
    "        for field, score in fields:\n",
    "            field_cn[field] += 1\n",
    "    else:\n",
    "        cn_not += 1\n",
    "\n",
    "for field, cn in field_cn.items():\n",
    "    if cn >= 500:\n",
    "        top_fields.append(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 8 papers do not have fields in MAG.\n",
    "cn_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ix = {fid: ix for ix, fid in enumerate(top_fields)}\n",
    "top_fields_colnames = [field_id2name_level[fid][0] for fid in top_fields]\n",
    "field_name_clean_map = {name: clean_field_name(name) for name in top_fields_colnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Social_psychology\", \"Psychology\", \"Astronomy\", \"Astrophysics\", \"Physics\", \"Population\", \"Pedagogy\", \"Cohort_study\", \"Computer_science\", \"Public_relations\", \"Business\", \"Ecology\", \"Predation\", \"Biology\", \"Environmental_resource_management\", \"Biodiversity\", \"Geomorphology\", \"Geology\", \"Atmospheric_sciences\", \"Personality\", \"Drug\", \"Alternative_medicine\", \"Psychological_intervention\", \"Medicine\", \"Habitat\", \"Ecosystem\", \"Mood\", \"Cognition\", \"Health_care\", \"Endocrinology\", \"Disease\", \"Internal_medicine\", \"Diabetes_mellitus\", \"Family_medicine\", \"Political_science\", \"Biochemistry\", \"Molecular_biology\", \"Breast_cancer\", \"Phenotype\", \"Cancer_research\", \"Cancer\", \"Immune_system\", \"In_vivo\", \"Oncology\", \"Chemotherapy\", \"Ethnic_group\", \"Environmental_health\", \"Cross_sectional_study\", \"Logistic_regression\", \"Odds_ratio\", \"Public_health\", \"Relative_risk\", \"Risk_factor\", \"Stroke\", \"Pathology\", \"Phenomenon\", \"Geography\", \"Chemistry\", \"Botany\", \"Nanotechnology\", \"Materials_science\", \"Neuroscience\", \"Offspring\", \"Receptor\", \"Surgery\", \"Demography\", \"Socioeconomic_status\", \"Pediatrics\", \"Epidemiology\", \"Anesthesia\", \"Distress\", \"Psychiatry\", \"Anxiety\", \"Quality_of_life\", \"Radiology\", \"Cell_biology\", \"Cohort\", \"Obesity\", \"Body_mass_index\", \"Gerontology\", \"Type_2_diabetes\", \"Genetics\", \"Genome\", \"Meta_analysis\", \"Artificial_intelligence\", \"Anatomy\", \"Hippocampus\", \"Intensive_care_medicine\", \"Clinical_trial\", \"Politics\", \"Mutation\", \"Immunology\", \"Paleontology\", \"Stimulus__physiology_\", \"Occupational_safety_and_health\", \"Medical_emergency\", \"Sociology\", \"Labour_economics\", \"Longitudinal_study\", \"Economic_growth\", \"Young_adult\", \"Physical_therapy\", \"Developmental_psychology\", \"Stem_cell\", \"Climatology\", \"Global_warming\", \"Climate_change\", \"Nursing\", \"Composite_material\", \"Autism\", \"Clinical_psychology\", \"Optoelectronics\", \"Suicide_prevention\", \"Virology\", \"Environmental_engineering\", \"Cardiology\", \"Evolutionary_biology\", \"Zoology\", \"Fishery\", \"Transcription_factor\", \"Myocardial_infarction\", \"Economics\", \"Greenhouse_gas\", \"Pharmacology\", \"Gene\", \"Food_science\", \"General_surgery\", \"Adverse_effect\", \"Proportional_hazards_model\", \"Prostate_cancer\", \"Oceanography\", \"Optics\", \"Placebo\", \"Emergency_medicine\", \"Vaccination\", \"Psychotherapist\", \"Applied_psychology\", \"Social_science\", \"Socioeconomics\", \"Injury_prevention\", \"Engineering\", \"Prospective_cohort_study\", \"Environmental_science\", \"Agriculture\", \"Communication\", \"Affect__psychology_\", \"Mental_health\", \"Human_factors_and_ergonomics\", \"Dementia\", \"Perception\", \"Geophysics\", \"Gynecology\", \"Retrospective_cohort_study\", \"Pregnancy\", \"Hazard_ratio\", \"Gene_expression\", \"Bioinformatics\", \"Epigenetics\", \"Marketing\", \"Feeling\", \"Inorganic_chemistry\", \"Public_administration\", \"Law\", \"Physical_medicine_and_rehabilitation\", \"Overweight\", \"Risk_assessment\", \"Emergency_department\", \"Comorbidity\", \"Confidence_interval\", \"Ranging\", \"Weight_loss\", \"Odds\", \"Insulin\", \"Condensed_matter_physics\", \"Signal_transduction\", \"Analytical_chemistry\", \"Cell\", \"Randomized_controlled_trial\", \"Cognitive_psychology\", \"Microbiology\", \"Bacteria\", \"Psychosocial\", \"Transplantation\", \"Biomarker__medicine_\", \"Blood_pressure\", \"Organic_chemistry\", \"Clinical_endpoint\", \"Observational_study\", \"Microeconomics\", \"Obstetrics\", \"Virus\", \"Heart_disease\", \"Antibiotics\", \"Inflammation\", \"Medical_prescription\", \"Gastroenterology\", \"Government\", \"Mortality_rate\", \"Antibody'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\", \"'.join(field_name_clean_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Social_psychology + Psychology + Astronomy + Astrophysics + Physics + Population + Pedagogy + Cohort_study + Computer_science + Public_relations + Business + Ecology + Predation + Biology + Environmental_resource_management + Biodiversity + Geomorphology + Geology + Atmospheric_sciences + Personality + Drug + Alternative_medicine + Psychological_intervention + Medicine + Habitat + Ecosystem + Mood + Cognition + Health_care + Endocrinology + Disease + Internal_medicine + Diabetes_mellitus + Family_medicine + Political_science + Biochemistry + Molecular_biology + Breast_cancer + Phenotype + Cancer_research + Cancer + Immune_system + In_vivo + Oncology + Chemotherapy + Ethnic_group + Environmental_health + Cross_sectional_study + Logistic_regression + Odds_ratio + Public_health + Relative_risk + Risk_factor + Stroke + Pathology + Phenomenon + Geography + Chemistry + Botany + Nanotechnology + Materials_science + Neuroscience + Offspring + Receptor + Surgery + Demography + Socioeconomic_status + Pediatrics + Epidemiology + Anesthesia + Distress + Psychiatry + Anxiety + Quality_of_life + Radiology + Cell_biology + Cohort + Obesity + Body_mass_index + Gerontology + Type_2_diabetes + Genetics + Genome + Meta_analysis + Artificial_intelligence + Anatomy + Hippocampus + Intensive_care_medicine + Clinical_trial + Politics + Mutation + Immunology + Paleontology + Stimulus__physiology_ + Occupational_safety_and_health + Medical_emergency + Sociology + Labour_economics + Longitudinal_study + Economic_growth + Young_adult + Physical_therapy + Developmental_psychology + Stem_cell + Climatology + Global_warming + Climate_change + Nursing + Composite_material + Autism + Clinical_psychology + Optoelectronics + Suicide_prevention + Virology + Environmental_engineering + Cardiology + Evolutionary_biology + Zoology + Fishery + Transcription_factor + Myocardial_infarction + Economics + Greenhouse_gas + Pharmacology + Gene + Food_science + General_surgery + Adverse_effect + Proportional_hazards_model + Prostate_cancer + Oceanography + Optics + Placebo + Emergency_medicine + Vaccination + Psychotherapist + Applied_psychology + Social_science + Socioeconomics + Injury_prevention + Engineering + Prospective_cohort_study + Environmental_science + Agriculture + Communication + Affect__psychology_ + Mental_health + Human_factors_and_ergonomics + Dementia + Perception + Geophysics + Gynecology + Retrospective_cohort_study + Pregnancy + Hazard_ratio + Gene_expression + Bioinformatics + Epigenetics + Marketing + Feeling + Inorganic_chemistry + Public_administration + Law + Physical_medicine_and_rehabilitation + Overweight + Risk_assessment + Emergency_department + Comorbidity + Confidence_interval + Ranging + Weight_loss + Odds + Insulin + Condensed_matter_physics + Signal_transduction + Analytical_chemistry + Cell + Randomized_controlled_trial + Cognitive_psychology + Microbiology + Bacteria + Psychosocial + Transplantation + Biomarker__medicine_ + Blood_pressure + Organic_chemistry + Clinical_endpoint + Observational_study + Microeconomics + Obstetrics + Virus + Heart_disease + Antibiotics + Inflammation + Medical_prescription + Gastroenterology + Government + Mortality_rate + Antibody'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' + '.join(field_name_clean_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['field_vector'] = reg_data['doi'].apply(get_field_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data[top_fields_colnames] = pd.DataFrame(reg_data.field_vector.values.tolist(), index = reg_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = reg_data.drop(columns=['field_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = reg_data.rename(columns=field_name_clean_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524052"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_data.to_csv(data_root+\"reg_data.csv\", index=False, header=True, encoding='utf-8')\n",
    "# reg_data = pd.read_csv(data_root+\"reg_data.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.drop(columns = list(field_name_clean_map.values())).to_csv(data_root+\"reg_data_plot.csv\", index=False, header=True, encoding='utf-8')\n",
    "# reg_data_plot = pd.read_csv(data_root+\"reg_data_plot.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Black names (vs. Ethnea and Wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = reg_data.loc[reg_data.author_eth_census == 'black'][['author_name', 'author_eth_census', 'author_eth_wiki_broad', 'author_eth_ethnea_broad']]\n",
    "tem = tem.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E. Robinson  &  black  &  English  &  English \\\\\n",
      "Momar Ndao  &  black  &  RomanceLanguage  &  African \\\\\n",
      "Angela F Harris  &  black  &  English  &  English \\\\\n",
      "Daddy Mata-Mbemba  &  black  &  RomanceLanguage  &  African \\\\\n",
      "A Bolu Ajiboye  &  black  &  African  &  African \\\\\n",
      "Lasana T. Harris  &  black  &  English  &  English \\\\\n",
      "John M. Harris  &  black  &  English  &  English \\\\\n",
      "Edwin S Robinson  &  black  &  English  &  English \\\\\n",
      "Eric A. Coleman  &  black  &  English  &  English \\\\\n",
      "Mp Coleman  &  black  &  English  &  English \\\\\n"
     ]
    }
   ],
   "source": [
    "subdf = tem.sample(10)\n",
    "for name, census, ethnea, wiki in zip(subdf.author_name, subdf.author_eth_census, subdf.author_eth_ethnea_broad, subdf.author_eth_wiki_broad):\n",
    "    print(name, ' & ', census, ' & ', ethnea, ' & ', wiki, '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show African names (vs. Census and Wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = reg_data.loc[reg_data.author_eth_ethnea_broad == 'African'][['author_name', 'author_eth_census', 'author_eth_wiki_broad', 'author_eth_ethnea_broad']]\n",
    "tem = tem.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alana Lelo  &  African  &  white  &  RomanceLanguage \\\\\n",
      "Samuel Lawn  &  African  &  white  &  English \\\\\n",
      "Saka S Ajibola  &  African  &  black  &  EastAsian \\\\\n",
      "Mosi Adesina Ifatunji  &  African  &  black  &  African \\\\\n",
      "Sebastian Giwa  &  African  &  white  &  African \\\\\n",
      "Olabisi Oduwole  &  African  &  white  &  African \\\\\n",
      "Chidi N. Obasi  &  African  &  white  &  African \\\\\n",
      "Habauka M. Kwaambwa  &  African  &  api  &  African \\\\\n",
      "Esther E Omaiye  &  African  &  white  &  African \\\\\n",
      "Aurel T. Tankeu  &  African  &  white  &  English \\\\\n"
     ]
    }
   ],
   "source": [
    "subdf = tem.sample(10, random_state = 10)\n",
    "for name, ethnea, census, wiki in zip(subdf.first_aut_name, subdf.eth_first_author, subdf.eth_first_author_census, subdf.eth_first_author_wiki_broad):\n",
    "    print(name, ' & ', ethnea, ' & ', census, ' & ', wiki, '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
