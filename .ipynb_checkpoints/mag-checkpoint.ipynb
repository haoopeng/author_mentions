{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_data_root = '/shared/0/projects/news-quotes/'\n",
    "mag_dir = '/shared/0/datasets/mag/raw_data/'\n",
    "\n",
    "def fpath(filename):\n",
    "    return os.path.join(media_data_root, filename)\n",
    "\n",
    "def yield_one_line(filename, delimiter=',', quoting = csv.QUOTE_ALL):\n",
    "    '''a generator which produce one line of a given file'''\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter=delimiter, quoting=quoting)\n",
    "        count = 0\n",
    "        for row in reader:\n",
    "            count += 1\n",
    "            if count % 10000000 == 0:\n",
    "                print('processed %d lines...' % (count))\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(media_data_root+'dois_mentioned.pickle', 'rb') as ofile:\n",
    "    dois_mentioned = pickle.load(ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in dois_mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292418"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_mentioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_to_doi = {}\n",
    "doi_to_pid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000000 lines...\n",
      "processed 20000000 lines...\n",
      "processed 30000000 lines...\n",
      "processed 40000000 lines...\n",
      "processed 50000000 lines...\n",
      "processed 60000000 lines...\n",
      "processed 70000000 lines...\n",
      "processed 80000000 lines...\n",
      "processed 90000000 lines...\n",
      "processed 100000000 lines...\n",
      "processed 110000000 lines...\n",
      "processed 120000000 lines...\n",
      "processed 130000000 lines...\n",
      "processed 140000000 lines...\n",
      "processed 150000000 lines...\n",
      "processed 160000000 lines...\n",
      "processed 170000000 lines...\n",
      "processed 180000000 lines...\n",
      "processed 190000000 lines...\n",
      "processed 200000000 lines...\n",
      "processed 210000000 lines...\n",
      "processed 220000000 lines...\n"
     ]
    }
   ],
   "source": [
    "for line in yield_one_line(mag_dir+'Papers.csv', delimiter=',', quoting=csv.QUOTE_ALL):\n",
    "    pid, doi = line[0], line[2]\n",
    "    # lowercase all DOIs\n",
    "    doi = doi.lower()\n",
    "    if doi in dois_mentioned:\n",
    "        pid_to_doi[pid] = doi\n",
    "        doi_to_pid[doi] = pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAG `pid` and `doi` is not uniquely matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279603"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pid_to_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doi_to_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10.1111/j.0042-7092.2007.00700.x', 325),\n",
       " ('10.4172/2327-5162.s1.006', 40),\n",
       " ('10.1002/ajpa.22718', 32),\n",
       " ('10.1096/fj.1530-6860', 18),\n",
       " ('10.4172/2155-9864-c1-028', 18),\n",
       " ('10.1017/cbo9780511606632', 16),\n",
       " ('10.1007/s10339-014-0632-2', 15),\n",
       " ('10.1001/jama.283.20.2653', 12),\n",
       " ('10.1017/cbo9780511977244', 12),\n",
       " ('10.1140/epjc/s10052-015-3451-4', 12)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(pid_to_doi.values()).items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148199778\n",
      "187660587\n",
      "1504222470\n",
      "1515456818\n",
      "1547332218\n",
      "1580475749\n",
      "1590605802\n",
      "1592369239\n",
      "1971009629\n",
      "2033690336\n",
      "2062676870\n",
      "2141124189\n"
     ]
    }
   ],
   "source": [
    "for pid, doi in pid_to_doi.items():\n",
    "    if doi == '10.1001/jama.283.20.2653':\n",
    "        print(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_valid = set()\n",
    "\n",
    "for doi, cn in Counter(pid_to_doi.values()).items():\n",
    "    if cn == 1:\n",
    "        dois_valid.add(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in list(pid_to_doi.keys()):\n",
    "    doi = pid_to_doi[pid]\n",
    "    if doi not in dois_valid:\n",
    "        del pid_to_doi[pid]\n",
    "        \n",
    "for doi in list(doi_to_pid.keys()):\n",
    "    if doi not in dois_valid:\n",
    "        del doi_to_pid[doi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269866"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pid_to_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269866"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doi_to_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228775246393861"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pid_to_doi) / len(dois_mentioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dois_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000000 lines...\n",
      "processed 20000000 lines...\n",
      "processed 30000000 lines...\n",
      "processed 40000000 lines...\n",
      "processed 50000000 lines...\n",
      "processed 60000000 lines...\n",
      "processed 70000000 lines...\n"
     ]
    }
   ],
   "source": [
    "dois_abs = {}\n",
    "\n",
    "for line in yield_one_line(mag_dir+'PaperAbstractsInvertedIndex.txt', delimiter='\\t', quoting=csv.QUOTE_NONE):\n",
    "    pid, abs_dict = line\n",
    "    try:\n",
    "        abs_dict = json.loads(abs_dict)\n",
    "    except:\n",
    "        continue\n",
    "    if pid in pid_to_doi:\n",
    "        doi = pid_to_doi[pid]\n",
    "        length = abs_dict[\"IndexLength\"]\n",
    "        text = [''] * length\n",
    "        for word, ixs in abs_dict['InvertedIndex'].items():\n",
    "            for ix in ixs:\n",
    "                text[ix] = word\n",
    "        dois_abs[doi] = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156679"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath('dois_abstract.json'), 'w') as ofile:\n",
    "    for doi, text in dois_abs.items():\n",
    "        row = {'doi': doi, 'abs': text}\n",
    "        ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_authors_mag = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000000 lines...\n",
      "processed 20000000 lines...\n",
      "processed 30000000 lines...\n",
      "processed 40000000 lines...\n",
      "processed 50000000 lines...\n",
      "processed 60000000 lines...\n",
      "processed 70000000 lines...\n",
      "processed 80000000 lines...\n",
      "processed 90000000 lines...\n",
      "processed 100000000 lines...\n",
      "processed 110000000 lines...\n",
      "processed 120000000 lines...\n",
      "processed 130000000 lines...\n",
      "processed 140000000 lines...\n",
      "processed 150000000 lines...\n",
      "processed 160000000 lines...\n",
      "processed 170000000 lines...\n",
      "processed 180000000 lines...\n",
      "processed 190000000 lines...\n",
      "processed 200000000 lines...\n",
      "processed 210000000 lines...\n",
      "processed 220000000 lines...\n",
      "processed 230000000 lines...\n",
      "processed 240000000 lines...\n",
      "processed 250000000 lines...\n",
      "processed 260000000 lines...\n",
      "processed 270000000 lines...\n",
      "processed 280000000 lines...\n",
      "processed 290000000 lines...\n",
      "processed 300000000 lines...\n",
      "processed 310000000 lines...\n",
      "processed 320000000 lines...\n",
      "processed 330000000 lines...\n",
      "processed 340000000 lines...\n",
      "processed 350000000 lines...\n",
      "processed 360000000 lines...\n",
      "processed 370000000 lines...\n",
      "processed 380000000 lines...\n",
      "processed 390000000 lines...\n",
      "processed 400000000 lines...\n",
      "processed 410000000 lines...\n",
      "processed 420000000 lines...\n",
      "processed 430000000 lines...\n",
      "processed 440000000 lines...\n",
      "processed 450000000 lines...\n",
      "processed 460000000 lines...\n",
      "processed 470000000 lines...\n",
      "processed 480000000 lines...\n",
      "processed 490000000 lines...\n",
      "processed 500000000 lines...\n",
      "processed 510000000 lines...\n",
      "processed 520000000 lines...\n",
      "processed 530000000 lines...\n",
      "processed 540000000 lines...\n",
      "processed 550000000 lines...\n",
      "processed 560000000 lines...\n",
      "processed 570000000 lines...\n",
      "processed 580000000 lines...\n",
      "processed 590000000 lines...\n"
     ]
    }
   ],
   "source": [
    "for line in yield_one_line(mag_dir+'PaperAuthorAffiliations.txt', delimiter='\\t', quoting=csv.QUOTE_NONE):\n",
    "    pid, aid, aff_id, seq, name = line[:5]\n",
    "    if pid in pid_to_doi:\n",
    "        doi = pid_to_doi[pid]\n",
    "        dois_authors_mag[doi].append((aid, aff_id, seq, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_authors_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_authors_mag) / len(doi_to_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('164305248', '', '7', 'Scott M Grundy'),\n",
       " ('171232130', '867280407', '6', 'Ramin Farzaneh-Far'),\n",
       " ('1691429694', '1299303238', '4', 'Tiffany M. Powell-Wiley'),\n",
       " ('1893993938', '', '1', 'Ian J. Neeland'),\n",
       " ('2008178114', '', '2', 'Aslan T. Turer'),\n",
       " ('2091543069', '', '9', 'Darren K McGuire'),\n",
       " ('2096306022', '', '5', 'Gloria Lena Vega'),\n",
       " ('2109761996', '', '8', 'Amit Khera'),\n",
       " ('2129691995', '', '3', 'Colby R. Ayers'),\n",
       " ('2560969913', '', '10', 'James A. de Lemos')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dois_authors_mag['10.1001/2012.jama.11132']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_authors_mag['10.1001/2012.jama.11132'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath('dois_authors_mag.json'), 'w') as ofile:\n",
    "    for doi in dois_authors_mag:\n",
    "        pid = doi_to_pid[doi]\n",
    "        authors = dois_authors_mag[doi]\n",
    "        row = {'doi': doi, 'mag_pid': pid, 'authors': authors}\n",
    "        ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aids = set()\n",
    "for doi in dois_authors_mag:\n",
    "    authors = dois_authors_mag[doi]\n",
    "    for aid, aff_id, seq, name in authors:\n",
    "#         seq = int(seq)\n",
    "#         if seq == 1:\n",
    "        all_aids.add(aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000000 lines...\n",
      "processed 20000000 lines...\n",
      "processed 30000000 lines...\n",
      "processed 40000000 lines...\n",
      "processed 50000000 lines...\n",
      "processed 60000000 lines...\n",
      "processed 70000000 lines...\n",
      "processed 80000000 lines...\n",
      "processed 90000000 lines...\n",
      "processed 100000000 lines...\n",
      "processed 110000000 lines...\n",
      "processed 120000000 lines...\n",
      "processed 130000000 lines...\n",
      "processed 140000000 lines...\n",
      "processed 150000000 lines...\n",
      "processed 160000000 lines...\n",
      "processed 170000000 lines...\n",
      "processed 180000000 lines...\n",
      "processed 190000000 lines...\n",
      "processed 200000000 lines...\n",
      "processed 210000000 lines...\n",
      "processed 220000000 lines...\n",
      "processed 230000000 lines...\n",
      "processed 240000000 lines...\n"
     ]
    }
   ],
   "source": [
    "aids_metric = dict()\n",
    "\n",
    "for line in yield_one_line(mag_dir+'Authors.txt', delimiter='\\t', quoting=csv.QUOTE_NONE):\n",
    "    aid, rank, num_paper, num_cite = line[0], line[1], line[5], line[6]\n",
    "    if aid in all_aids:\n",
    "        aids_metric[aid] = (rank, num_paper, num_cite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041143"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aids_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath('aids_metric_mag.json'), 'w') as ofile:\n",
    "    for aid, info in aids_metric.items():\n",
    "        row = {'aid': aid, 'metric': info}\n",
    "        ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dois_disc = defaultdict(list)\n",
    "\n",
    "for line in yield_one_line(mag_dir+'PaperFieldsOfStudy.txt', delimiter='\\t', quoting=csv.QUOTE_NONE):\n",
    "    pid, fid, frac = line\n",
    "    frac = float(frac)\n",
    "    if pid in pid_to_doi:\n",
    "        doi = pid_to_doi[pid]\n",
    "        dois_disc[doi].append((fid, frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268867"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2780320433', 0.526666343),\n",
       " ('2779668308', 0.6762392),\n",
       " ('2780221984', 0.5918762),\n",
       " ('511355011', 0.544381559),\n",
       " ('2777391703', 0.6243656),\n",
       " ('555293320', 0.591008365),\n",
       " ('2910068830', 0.600785553),\n",
       " ('141071460', 0.387458026),\n",
       " ('2777180221', 0.6201425),\n",
       " ('71924100', 0.410550684)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dois_disc['10.1001/2012.jama.11132']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath('dois_fields_mag.json'), 'w') as ofile:\n",
    "    for doi in dois_disc:\n",
    "        fields = dois_disc[doi]\n",
    "        row = {'doi': doi, 'fields': fields}\n",
    "        ofile.write(json.dumps(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
