{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from spacy.lang.en import English # updated\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/shared/0/projects/news-quotes/reg_data_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'doi', 'author_id', 'affiliation_ids', 'author_seq_num',\n",
       "       'author_name', 'author_pos_cate', 'author_last_name',\n",
       "       'last_name_length', 'last_name_prob', 'author_eth_ethnea',\n",
       "       'author_gender_ethnea', 'author_eth_wiki', 'author_eth_census',\n",
       "       'reporter_name', 'reporter_eth_ethnea', 'reporter_gender_ethnea',\n",
       "       'reporter_eth_wiki', 'reporter_eth_census', 'author_eth_ethnea_broad',\n",
       "       'reporter_eth_ethnea_broad', 'author_eth_wiki_broad',\n",
       "       'reporter_eth_wiki_broad', 'is_top_author', 'doi_men_cn', 'author_rank',\n",
       "       'affiliation_cate', 'affiliation_rank', 'journal_title',\n",
       "       'journal_impact', 'top_journal', 'num_authors', 'outlet', 'category',\n",
       "       'num_words', 'num_mentioned_papers', 'mention_year',\n",
       "       'mention_year_center', 'gap_in_years', 'is_author_mentioned',\n",
       "       'FleschReadingEase', 'sentences_per_paragraph', 'type_token_ratio',\n",
       "       'Publication Date', 'Mention Date', 'is_corresponding',\n",
       "       'affiliation_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520061\n"
     ]
    }
   ],
   "source": [
    "urls_text = {}\n",
    "\n",
    "with open('/shared/0/projects/news-quotes/crawl_news/url_text_clean.json', 'r') as ofile:\n",
    "    for row in ofile:\n",
    "        row = json.loads(row)\n",
    "        url, text = row['url'], row['text']\n",
    "        urls_text[url] = text\n",
    "print(len(urls_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 [('Cambridge', 1)] \n",
      "\n",
      "20712 50000 [('California', 3306), ('Hospital', 1776), ('Harvard', 1568), ('Health', 1490), ('London', 1242), ('San', 1117), ('Washington', 1034), ('Pennsylvania', 941), ('Johns', 845), ('Hopkins', 845)] \n",
      "\n",
      "41598 100000 [('California', 6382), ('Hospital', 3488), ('Harvard', 3216), ('Health', 2993), ('London', 2376), ('San', 2125), ('Washington', 1900), ('Pennsylvania', 1883), ('Science', 1754), ('Johns', 1638)] \n",
      "\n",
      "62622 150000 [('California', 9268), ('Hospital', 5100), ('Harvard', 4845), ('Health', 4608), ('London', 3666), ('San', 3087), ('Washington', 3045), ('Pennsylvania', 2680), ('Science', 2619), ('Texas', 2482)] \n",
      "\n",
      "82981 200000 [('California', 12222), ('Hospital', 6627), ('Harvard', 6437), ('Health', 6075), ('London', 4901), ('San', 4162), ('Washington', 3921), ('Pennsylvania', 3583), ('Science', 3559), ('New', 3326)] \n",
      "\n",
      "94488 250000 [('California', 15241), ('Harvard', 8422), ('Hospital', 8287), ('Health', 7648), ('London', 6438), ('San', 5152), ('Washington', 4985), ('Pennsylvania', 4356), ('Science', 4253), ('New', 4202)] \n",
      "\n",
      "114458 300000 [('California', 19050), ('Hospital', 10132), ('Harvard', 10014), ('Health', 9343), ('London', 7653), ('San', 6505), ('Washington', 6363), ('Pennsylvania', 5368), ('Science', 5138), ('Johns', 5007)] \n",
      "\n",
      "134503 350000 [('California', 22637), ('Hospital', 12098), ('Harvard', 11906), ('Health', 10781), ('London', 8676), ('San', 7847), ('Washington', 7654), ('Pennsylvania', 6260), ('Johns', 5934), ('Hopkins', 5933)] \n",
      "\n",
      "154547 400000 [('California', 25756), ('Hospital', 14099), ('Harvard', 13785), ('Health', 12454), ('London', 9755), ('San', 8973), ('Washington', 8936), ('Pennsylvania', 7377), ('Johns', 6815), ('Hopkins', 6814)] \n",
      "\n",
      "175622 450000 [('California', 29153), ('Hospital', 15668), ('Harvard', 15337), ('Health', 14285), ('London', 11123), ('Washington', 10427), ('San', 9853), ('Pennsylvania', 8152), ('New', 7727), ('Michigan', 7680)] \n",
      "\n",
      "195568 500000 [('California', 32161), ('Hospital', 17241), ('Harvard', 16988), ('Health', 15833), ('London', 12248), ('Washington', 11602), ('San', 11094), ('Pennsylvania', 9193), ('New', 8615), ('Michigan', 8530)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_counts = Counter()\n",
    "    \n",
    "def has_indirect_mention(text, univ):\n",
    "    #print(\"LAST NAME: '%s'\" % fa_last_name)\n",
    "    \n",
    "    \n",
    "    # See if we can find a \"said\"-like verb to indicate they gave the quote\n",
    "    has_mention = False\n",
    "    has_mention_weaker = False\n",
    "    \n",
    "    univ_keywords = re.split(r\"\\W+\", univ)\n",
    "    blacklist = set(['University', 'the', 'Technology', 'of', 'Research', 'for', \n",
    "                     'Institute', 'Medical', 's', 'and', 'National', 'Center',\n",
    "                    'College', 'State', 'at'])\n",
    "    univ_keywords = [x for x in univ_keywords if x not in blacklist] \n",
    "    for kw in univ_keywords:\n",
    "        keyword_counts[kw] += 1\n",
    "    \n",
    "    #if 'Chinese sex wizards' in text:\n",
    "    #    print(text)\n",
    "    \n",
    "    if False:\n",
    "        sentences = [i for i in nlp(text).sents]\n",
    "        for sent in sentences:\n",
    "\n",
    "            if has_mention or has_mention_weaker:\n",
    "                break\n",
    "\n",
    "            sent_text = ' '.join([t.text for t in sent])\n",
    "            #print(univ, sent_text)\n",
    "            if univ in sent_text:\n",
    "                has_mention = True\n",
    "            if first_word in sent_text:\n",
    "                has_mention_weaker = True\n",
    "    else:\n",
    "        if univ in text:\n",
    "            has_mention = True\n",
    "            i = text.find(univ)\n",
    "            sent_text = ' '.join(text[i-50:i+50+len(univ)].split())\n",
    "        for keyword in univ_keywords:\n",
    "            if keyword in text:\n",
    "                has_mention_weaker = True\n",
    "                i = text.find(keyword)\n",
    "                sent_text = ' '.join(text[i-20:i+20+len(keyword)].split())\n",
    "                break\n",
    "                \n",
    "    if has_mention:\n",
    "        #print(\"Found a indirect mention of '%s':\\n  %s\\n\" % (univ, sent_text))\n",
    "        pass\n",
    "    elif has_mention_weaker:\n",
    "        #print(\"Found a POSSIBLE indirect mention of '%s' via '%s':\\n  %s\\n\" % (univ, keyword, sent_text))\n",
    "        pass            \n",
    "    else:\n",
    "        #print(\"NO QUOTE by %s:\\n  %s\\n\" % (fa_last_name, \" \".join(str(sent_text).split())))\n",
    "        pass\n",
    "\n",
    "\n",
    "    return has_mention # or has_mention_weaker\n",
    "            \n",
    "\n",
    "has_indirect_mention_col = []\n",
    "im_count = 0\n",
    "\n",
    "if True:\n",
    "    for ri, row in df.iterrows():\n",
    "        url = row['url']\n",
    "        text = urls_text[url]\n",
    "        univs = row['affiliation_name'].split('|')\n",
    "        him = False\n",
    "        # if any one of univs is mentioned, it is positive.\n",
    "        for university in univs:\n",
    "            if has_indirect_mention(text, university):\n",
    "                him = True\n",
    "                break\n",
    "        has_indirect_mention_col.append(him)\n",
    "        if him:\n",
    "            im_count += 1\n",
    "        if ri % 50000 == 0:\n",
    "            print(im_count, ri, keyword_counts.most_common(10), '\\n')\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mentions_author_institution'] = has_indirect_mention_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "him_col = []\n",
    "for i, row in df.iterrows():\n",
    "    him = (row['is_author_mentioned'] < 1) and row['mentions_author_institution'] \n",
    "    him_col.append(him)\n",
    "df['has_indirect_mention'] = him_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['url', 'has_indirect_mention', 'mentions_author_institution']].to_csv('/shared/0/projects/news-quotes/crawl_news/has_indirect_quote.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
